{"id":"bd-077e","title":"Add close_reason field to CLI schema and documentation","description":"PR #551 persists close_reason, but the CLI documentation may not mention this field as part of the issue schema.\n\n## Current State\n- close_reason is now persisted in database\n- `bd show --json` will return close_reason in JSON output\n- Documentation may not reflect this new field\n\n## What's Missing\n- CLI reference documentation for close_reason field\n- Schema documentation showing close_reason is a top-level issue field\n- Example output showing close_reason in bd show --json\n- bd close command documentation should mention close_reason parameter is optional\n\n## Suggested Action\n1. Update README.md or CLI reference docs to list close_reason as an issue field\n2. Add example to bd close documentation\n3. Update any type definitions or schema specs\n4. Consider adding close_reason to verbose list output (bd list --verbose)","status":"open","priority":3,"issue_type":"task","created_at":"2025-12-14T14:25:28.448654-08:00","updated_at":"2025-12-14T14:25:28.448654-08:00","dependencies":[{"issue_id":"bd-077e","depends_on_id":"bd-z86n","type":"discovered-from","created_at":"2025-12-14T14:25:28.449968-08:00","created_by":"stevey"}]}
{"id":"bd-08ea","title":"bd cleanup should also prune expired tombstones","description":"## Problem\n\nbd cleanup deletes closed issues (converting them to tombstones) but does NOT prune expired tombstones. Users expect 'cleanup' to do comprehensive cleanup.\n\n## Current Behavior\n\n1. bd cleanup --force converts closed issues to tombstones\n2. Expired tombstones (\u003e30 days) remain in issues.jsonl  \n3. User must separately run bd compact to prune tombstones\n4. bd doctor warns about expired tombstones: Run bd compact to prune\n\n## Expected Behavior\n\nbd cleanup should also prune expired tombstones from issues.jsonl.\n\n## Impact\n\nWith v0.30.0 making tombstones the default migration path, this UX gap becomes more visible. Users cleaning up their database should not need to know about a separate bd compact command.\n\n## Proposed Solution\n\nCall pruneExpiredTombstones() at the end of the cleanup command (same function used by compact).\n\n## Files to Modify\n\n- cmd/bd/cleanup.go - Add call to pruneExpiredTombstones after deleteBatch\n\n## Acceptance Criteria\n\n- bd cleanup --force prunes expired tombstones after deleting closed issues\n- bd cleanup --dry-run shows what tombstones would be pruned\n- JSON output includes tombstone prune results","status":"closed","priority":1,"issue_type":"bug","created_at":"2025-12-14T00:27:34.718433-08:00","updated_at":"2025-12-14T00:41:54.583522-08:00","closed_at":"2025-12-14T00:36:44.488769-08:00"}
{"id":"bd-0a43","title":"Split monolithic sqlite.go into focused files","description":"internal/storage/sqlite/sqlite.go is 1050 lines containing initialization, 20+ CRUD methods, query building, and schema management.\n\nSplit into:\n- store.go: Store struct \u0026 initialization (150 lines)\n- bead_queries.go: Bead CRUD (300 lines)\n- work_queries.go: Work queries (200 lines)  \n- stats_queries.go: Statistics (150 lines)\n- schema.go: Schema \u0026 migrations (150 lines)\n- helpers.go: Common utilities (100 lines)\n\nImpact: Impossible to understand at a glance; hard to find specific functionality; high cognitive load\n\nEffort: 6-8 hours","status":"open","priority":0,"issue_type":"task","created_at":"2025-11-16T14:51:16.520465-08:00","updated_at":"2025-11-16T14:51:16.520465-08:00"}
{"id":"bd-0fvq","title":"bd doctor should recommend bd prime migration for existing repos","description":"bd doctor should detect old beads integration patterns and recommend migrating to bd prime approach.\n\n## Current behavior\n- bd doctor checks if Claude hooks are installed globally\n- Doesn't check project-level integration (AGENTS.md, CLAUDE.md)\n- Doesn't recommend migration for repos using old patterns\n\n## Desired behavior\nbd doctor should detect and suggest:\n\n1. **Old slash command pattern detected**\n   - Check for /beads:* references in AGENTS.md, CLAUDE.md\n   - Suggest: These slash commands are deprecated, use bd prime hooks instead\n   \n2. **No agent documentation**\n   - Check if AGENTS.md or CLAUDE.md exists\n   - Suggest: Run 'bd onboard' or 'bd setup claude' to document workflow\n   \n3. **Old MCP-only pattern**\n   - Check for instructions to use MCP tools but no bd prime hooks\n   - Suggest: Add bd prime hooks for better token efficiency\n\n4. **Migration path**\n   - Show: 'Run bd setup claude to add SessionStart/PreCompact hooks'\n   - Show: 'Update AGENTS.md to reference bd prime instead of slash commands'\n\n## Example output\n\n‚ö† Warning: Old beads integration detected in CLAUDE.md\n  Found: /beads:* slash command references (deprecated)\n  Recommend: Migrate to bd prime hooks for better token efficiency\n  Fix: Run 'bd setup claude' and update CLAUDE.md\n\nüí° Tip: bd prime + hooks reduces token usage by 80-99% vs slash commands\n  MCP mode: ~50 tokens vs ~10.5k for full MCP scan\n  CLI mode: ~1-2k tokens with automatic context recovery\n\n## Benefits\n- Helps existing repos adopt new best practices\n- Clear migration path for users\n- Better token efficiency messaging","status":"open","priority":2,"issue_type":"feature","created_at":"2025-11-12T03:20:25.567748-08:00","updated_at":"2025-11-12T03:20:25.567748-08:00"}
{"id":"bd-0yzm","title":"GH#508: Orphan detection false positive when directory name contains dot","description":"Directory names with dots trigger orphan issue detection because dot is also used for orphan ID format. bd rename-prefix fixes it. See: https://github.com/steveyegge/beads/issues/508","status":"in_progress","priority":2,"issue_type":"bug","created_at":"2025-12-14T16:32:01.725196-08:00","updated_at":"2025-12-14T16:52:49.802533-08:00"}
{"id":"bd-19er","title":"Create backup and restore procedures","description":"Disaster recovery procedures for Agent Mail data.\n\nAcceptance Criteria:\n- Automated daily snapshots (GCP persistent disk)\n- SQLite backup script\n- Git repository backup\n- Restore procedure documentation\n- Test restore from backup\n\nFile: deployment/agent-mail/backup.sh","status":"closed","priority":3,"issue_type":"task","created_at":"2025-11-07T22:43:43.417403-08:00","updated_at":"2025-12-14T00:32:11.045902-08:00","closed_at":"2025-12-13T23:30:58.726086-08:00","dependencies":[{"issue_id":"bd-19er","depends_on_id":"bd-z3s3","type":"blocks","created_at":"2025-11-07T23:04:28.122501-08:00","created_by":"daemon"}]}
{"id":"bd-1a6j","title":"Test issue 2","description":"","status":"closed","priority":2,"issue_type":"task","created_at":"2025-11-07T19:07:12.24632-08:00","updated_at":"2025-12-13T23:29:56.877225-08:00","closed_at":"2025-12-13T23:29:56.877225-08:00"}
{"id":"bd-1rh","title":"cmd/bd test suite is absurdly slow - 279 tests taking 8+ minutes","description":"# Problem\n\nThe cmd/bd test suite is painfully slow:\n- **279 tests** in cmd/bd alone\n- Full suite takes **8+ minutes** to run\n- Even with the 16 slowest integration tests now tagged with `integration` build tag, the remaining tests still take forever\n\nThis makes the development loop unusable. We can't wait 8+ minutes every time we want to run tests.\n\n# Root Cause Analysis\n\n## 1. Sheer Volume\n279 tests is too many for a single package. Even at 0.1s per test, that's 28 seconds minimum just for cmd/bd.\n\n## 2. Each Test Creates Full Database + Temp Directories\nEvery test does heavy setup:\n- Creates temp directory (`t.TempDir()` or `os.MkdirTemp`)\n- Initializes SQLite database\n- Sets up git repo in many cases\n- Creates full storage layer\n\nExample from the tests:\n```go\nfunc setupCLITestDB(t *testing.T) string {\n    tmpDir := createTempDirWithCleanup(t)\n    runBDInProcess(t, tmpDir, \"init\", \"--prefix\", \"test\", \"--quiet\")\n    return tmpDir\n}\n```\n\nThis happens 279 times!\n\n## 3. Tests Are Not Properly Categorized\nWe have three types of tests mixed together:\n- **Unit tests** - should be fast, test single functions\n- **Integration tests** - test full workflows, need DB/git\n- **End-to-end tests** - test entire CLI commands\n\nThey're all lumped together in cmd/bd, all running every time.\n\n# What We've Already Fixed\n\nAdded `integration` build tags to 16 obviously-slow test files:\n- import_profile_test.go (performance benchmarking tests)\n- export_mtime_test.go (tests with time.Sleep calls)\n- cli_fast_test.go (full CLI integration tests)\n- delete_test.go, import_uncommitted_test.go, sync_local_only_test.go (git integration)\n- And 10 more in internal/ packages\n\nThese are now excluded from the default `go test ./...` run.\n\n# Proposed Solutions\n\n## Option 1: Shared Test Fixtures (Quick Win)\nCreate a shared test database that multiple tests can use:\n```go\nvar testDB *sqlite.SQLiteStorage\nvar testDBOnce sync.Once\n\nfunc getSharedTestDB(t *testing.T) storage.Storage {\n    testDBOnce.Do(func() {\n        // Create one DB for all tests\n    })\n    return testDB\n}\n```\n\n**Pros**: Easy to implement, immediate speedup\n**Cons**: Tests become less isolated, harder to debug failures\n\n## Option 2: Table-Driven Tests (Medium Win)\nCollapse similar tests into table-driven tests:\n```go\nfunc TestCreate(t *testing.T) {\n    tests := []struct{\n        name string\n        args []string\n        want string\n    }{\n        {\"basic issue\", []string{\"create\", \"Test\"}, \"created\"},\n        {\"with description\", []string{\"create\", \"Test\", \"-d\", \"desc\"}, \"created\"},\n        // ... 50 more cases\n    }\n    \n    db := setupOnce(t) // Setup once, not 50 times\n    for _, tt := range tests {\n        t.Run(tt.name, func(t *testing.T) {\n            // test using shared db\n        })\n    }\n}\n```\n\n**Pros**: Dramatically reduces setup overhead, tests run in parallel\n**Cons**: Requires refactoring, tests share more state\n\n## Option 3: Split cmd/bd Tests Into Packages (Big Win)\nMove tests into focused packages:\n- `cmd/bd/internal/clitests` - CLI integration tests (mark with integration tag)\n- `cmd/bd/internal/unittests` - Fast unit tests\n- Keep only essential tests in cmd/bd\n\n**Pros**: Clean separation, easy to run just fast tests\n**Cons**: Requires significant refactoring\n\n## Option 4: Parallel Execution (Quick Win)\nAdd `t.Parallel()` to independent tests:\n```go\nfunc TestSomething(t *testing.T) {\n    t.Parallel() // Run this test concurrently with others\n    // ...\n}\n```\n\n**Pros**: Easy to add, can cut time in half on multi-core machines\n**Cons**: Doesn't reduce actual test work, just parallelizes it\n\n## Option 5: In-Memory Databases (Medium Win)\nUse `:memory:` SQLite databases instead of file-based:\n```go\nstore, err := sqlite.New(ctx, \":memory:\")\n```\n\n**Pros**: Faster than disk I/O, easier cleanup\n**Cons**: Some tests need actual file-based DBs (export/import tests)\n\n# Recommended Approach\n\n**Short-term (this week)**:\n1. Add `t.Parallel()` to all independent tests in cmd/bd\n2. Use `:memory:` databases where possible\n3. Create table-driven tests for similar test cases\n\n**Medium-term (next sprint)**:\n4. Split cmd/bd tests into focused packages\n5. Mark more integration tests appropriately\n\n**Long-term (backlog)**:\n6. Consider shared test fixtures with proper isolation\n\n# Current Status\n\nWe've tagged 16 files with `integration` build tag, but the remaining 279 tests in cmd/bd still take 8+ minutes. This issue tracks fixing the cmd/bd test performance specifically.\n\n# Target\n\nGet `go test ./...` (without `-short` or `-tags=integration`) down to **under 30 seconds**.\n\n\n# THE REAL ROOT CAUSE (Updated Analysis)\n\nAfter examining the actual test code, the problem is clear:\n\n## Every Test Creates Its Own Database From Scratch\n\nLook at `create_test.go`:\n```go\nfunc TestCreate_BasicIssue(t *testing.T) {\n    tmpDir := t.TempDir()                          // ‚Üê Creates temp dir\n    testDB := filepath.Join(tmpDir, \".beads\", \"beads.db\")\n    s := newTestStore(t, testDB)                   // ‚Üê Opens NEW SQLite connection\n                                                    // ‚Üê Runs migrations\n                                                    // ‚Üê Sets config\n    // ... actual test (3 lines)\n}\n\nfunc TestCreate_WithDescription(t *testing.T) {\n    tmpDir := t.TempDir()                          // ‚Üê Creates ANOTHER temp dir\n    testDB := filepath.Join(tmpDir, \".beads\", \"beads.db\")\n    s := newTestStore(t, testDB)                   // ‚Üê Opens ANOTHER SQLite connection\n    // ... actual test (3 lines)\n}\n```\n\n**This happens 279 times!**\n\n## These Tests Don't Need Isolation!\n\nMost tests are just checking:\n- \"Can I create an issue with a title?\"\n- \"Can I create an issue with a description?\"\n- \"Can I add labels?\"\n\nThey don't conflict with each other. They could all share ONE database!\n\n## The Fix: Test Suites with Shared Setup\n\nInstead of:\n```go\nfunc TestCreate_BasicIssue(t *testing.T) {\n    s := newTestStore(t, t.TempDir()+\"/db\")  // ‚Üê Expensive!\n    // test\n}\n\nfunc TestCreate_WithDesc(t *testing.T) {\n    s := newTestStore(t, t.TempDir()+\"/db\")  // ‚Üê Expensive!\n    // test\n}\n```\n\nDo this:\n```go\nfunc TestCreate(t *testing.T) {\n    // ONE setup for all subtests\n    s := newTestStore(t, t.TempDir()+\"/db\")\n    \n    t.Run(\"basic_issue\", func(t *testing.T) {\n        t.Parallel()  // Can run concurrently - tests don't conflict\n        // test using shared `s`\n    })\n    \n    t.Run(\"with_description\", func(t *testing.T) {\n        t.Parallel()\n        // test using shared `s`\n    })\n    \n    // ... 50 more subtests, all using same DB\n}\n```\n\n**Result**: 50 tests ‚Üí 1 database setup instead of 50!\n\n## Why This Works\n\nSQLite is fine with concurrent reads and isolated transactions. These tests:\n- ‚úÖ Create different issues (no ID conflicts)\n- ‚úÖ Just read back what they created\n- ‚úÖ Don't depend on database state from other tests\n\nThey SHOULD share a database!\n\n## Real Numbers\n\nCurrent:\n- 279 tests √ó (create dir + init SQLite + migrations) = **8 minutes**\n\nAfter fix:\n- 10 test suites √ó (create dir + init SQLite + migrations) = **30 seconds**\n- 279 subtests running in parallel using those 10 DBs = **5 seconds**\n\n**Total: ~35 seconds instead of 8 minutes!**\n\n## Implementation Plan\n\n1. **Group related tests** into suites (Create, List, Update, Delete, etc.)\n2. **One setup per suite** instead of per test\n3. **Use t.Run() for subtests** with t.Parallel()\n4. **Keep tests that actually need isolation** separate (export/import tests, git operations)\n\nThis is way better than shuffling tests into folders!","notes":"## Progress Update (2025-11-21)\n\n‚úÖ **Completed**:\n- Audited all 280 tests, created TEST_SUITE_AUDIT.md ([deleted:bd-c49])\n- Refactored create_test.go to shared DB pattern ([deleted:bd-y6d])\n- Proven the pattern works: 11 tests now run in 0.04s with 1 DB instead of 11\n\n‚ùå **Current Reality**:\n- Overall test suite: Still 8+ minutes (no meaningful change)\n- Only 1 of 76 test files refactored\n- Saved ~10 DB initializations out of 280\n\n## Acceptance Criteria (REALISTIC)\n\nThis task is NOT complete until:\n- [ ] All P1 files refactored (create ‚úÖ, dep, stale, comments, list, ready)\n- [ ] Test suite runs in \u003c 2 minutes\n- [ ] Measured and verified actual speedup\n\n## Next Steps\n\n1. Refactor remaining 5 P1 files: dep_test.go, stale_test.go, comments_test.go, list_test.go, ready_test.go\n2. Measure actual time improvement after each file\n3. Continue with P2 files if needed to hit \u003c2min target","status":"open","priority":1,"issue_type":"bug","created_at":"2025-11-21T11:37:47.886207-05:00","updated_at":"2025-11-22T14:57:44.480203204-05:00"}
{"id":"bd-1tw","title":"Fix G104 errors unhandled in internal/storage/sqlite/queries.go:1186","description":"Linting issue: G104: Errors unhandled (gosec) at internal/storage/sqlite/queries.go:1186:2. Error: rows.Close()","status":"open","priority":0,"issue_type":"bug","created_at":"2025-12-07T15:35:13.051671889-07:00","updated_at":"2025-12-07T15:35:13.051671889-07:00"}
{"id":"bd-1vv","title":"Add WebSocket support","description":"## Feature Request\n\n[Describe the desired feature]\n\n## Motivation\n\n[Why is this feature needed? What problem does it solve?]\n\n## Use Cases\n\n1. **Use Case 1**: [description]\n2. **Use Case 2**: [description]\n\n## Proposed Solution\n\n[High-level approach to implementing this feature]\n\n## Alternatives Considered\n\n- **Alternative 1**: [description and why not chosen]\n- **Alternative 2**: [description and why not chosen]\n","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-11-03T19:56:41.271215-08:00","updated_at":"2025-12-13T23:30:18.69345-08:00","closed_at":"2025-12-13T23:30:18.69345-08:00"}
{"id":"bd-20j","title":"sync branch not match config","description":"./bd sync\n‚Üí Exporting pending changes to JSONL...\n‚Üí No changes to commit\n‚Üí Pulling from sync branch 'gh-386'...\nError pulling from sync branch: failed to create worktree: failed to create worktree parent directory: mkdir /var/home/matt/dev/beads/worktree-db-fail/.git: not a directory\nmatt@blufin-framation ~/d/b/worktree-db-fail (worktree-db-fail) [1]\u003e bd config list\n\nConfiguration:\n  auto_compact_enabled = false\n  compact_batch_size = 50\n  compact_model = claude-3-5-haiku-20241022\n  compact_parallel_workers = 5\n  compact_tier1_days = 30\n  compact_tier1_dep_levels = 2\n  compact_tier2_commits = 100\n  compact_tier2_days = 90\n  compact_tier2_dep_levels = 5\n  compaction_enabled = false\n  issue_prefix = worktree-db-fail\n  sync.branch = worktree-db-fail","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-08T06:49:04.449094018-07:00","updated_at":"2025-12-08T06:49:04.449094018-07:00"}
{"id":"bd-28db","title":"Add 'bd status' command for issue database overview","description":"Implement a bd status command that provides a quick snapshot of the issue database state, similar to how git status shows working tree state.\n\nExpected output: Show summary including counts by state (open, in-progress, blocked, closed), recent activity (last 7 days), and quick overview without needing multiple queries.\n\nExample output showing issue counts, recent activity stats, and pointer to bd list for details.\n\nProposed options: --all (show all issues), --assigned (show issues assigned to current user), --json (JSON format output)\n\nUse cases: Quick project health check, onboarding for new contributors, integration with shell prompts or CI/CD, daily standup reference","status":"open","priority":2,"issue_type":"feature","created_at":"2025-11-02T17:25:59.203549-08:00","updated_at":"2025-11-02T17:25:59.203549-08:00"}
{"id":"bd-2k5f","title":"GH#510: Document sync-branch worktree behavior","description":"User confused about beads creating worktree on main branch. Need docs explaining sync-branch worktree mechanism. See: https://github.com/steveyegge/beads/issues/510","status":"in_progress","priority":3,"issue_type":"task","created_at":"2025-12-14T16:31:58.800071-08:00","updated_at":"2025-12-14T16:52:49.802181-08:00"}
{"id":"bd-2kf8","title":"Document CompactedResult response format in CONTEXT_ENGINEERING.md","description":"The CompactedResult is a new response format that MCP clients need to understand, but it's not documented in CONTEXT_ENGINEERING.md.\n\n## What's Missing\n- Example CompactedResult JSON response\n- How to detect if a result is compacted\n- How to request full results (disable compaction or increase limit)\n- Guidance on handling both list[IssueMinimal] and CompactedResult return types\n- Migration guide for clients expecting list[Issue] from ready() and list()\n\n## Documentation Gaps\nCurrently CONTEXT_ENGINEERING.md explains the optimization strategy but doesn't show:\n1. Sample CompactedResult response\n2. Client-side code examples for handling compaction\n3. When compaction is triggered (\u003e20 results)\n4. How to get all results if needed\n\n## Suggested Additions\nAdd new section \\\"Handling Large Result Sets\\\" with:\n- CompactedResult schema documentation\n- Python client example for handling both response types\n- Guidance on re-issuing queries with better filters","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-14T14:24:45.216616-08:00","updated_at":"2025-12-14T14:37:15.205803-08:00","closed_at":"2025-12-14T14:37:15.205803-08:00","dependencies":[{"issue_id":"bd-2kf8","depends_on_id":"bd-otf4","type":"discovered-from","created_at":"2025-12-14T14:24:45.217962-08:00","created_by":"stevey"}]}
{"id":"bd-2q6d","title":"Beads commands operate on stale database without warning","description":"All beads read operations should validate database is in sync with JSONL before proceeding.\n\n**Current Behavior:**\n- Commands can query/read from stale database\n- Only mutation operations (like 'bd sync') check if JSONL is newer\n- User gets incorrect results without realizing database is out of sync\n\n**Expected Behavior:**\n- All beads commands should have pre-flight check for database freshness\n- If JSONL is newer than database, refuse to operate with error: \"Database out of sync. Run 'bd import' first.\"\n- Same safety check that exists for 'bd sync' should apply to ALL operations\n\n**Impact:**\n- Users make decisions based on incomplete/outdated data\n- Silent failures lead to confusion (e.g., thinking issues don't exist when they do)\n- Similar to running git commands on stale repo without being warned to pull\n\n**Example:**\n- Searched for bd-g9eu issue file: not found\n- Issue exists in .beads/issues.jsonl (in git)\n- Database was stale, but no warning was given\n- Led to incorrect conclusion that issue was already closed/deleted","notes":"## Implementation Complete\n\n**Phase 1: Created staleness check (cmd/bd/staleness.go)**\n- ensureDatabaseFresh() function checks JSONL mtime vs last_import_time\n- Returns error with helpful message when database is stale\n- Auto-skips in daemon mode (daemon has auto-import)\n\n**Phase 2: Added to all read commands**\n- list, show, ready, status, stale, info, duplicates, validate\n- Check runs before database queries in direct mode\n- Daemon mode already protected via checkAndAutoImportIfStale()\n\n**Phase 3: Code Review Findings**\nSee follow-up issues:\n- bd-XXXX: Add warning when staleness check errors\n- bd-YYYY: Improve CheckStaleness error handling\n- bd-ZZZZ: Refactor redundant daemon checks (low priority)\n\n**Testing:**\n- Build successful: go build ./cmd/bd\n- Binary works: ./bd --version\n- Ready for manual testing\n\n**Next Steps:**\n1. Test with stale database scenario\n2. Implement review improvements\n3. Close issue when tests pass","status":"open","priority":1,"issue_type":"bug","created_at":"2025-11-20T19:33:40.019297-05:00","updated_at":"2025-11-22T14:57:44.481917204-05:00"}
{"id":"bd-2r1b","title":"fix: bd onboard hangs on Windows","description":"","status":"closed","priority":1,"issue_type":"bug","created_at":"2025-12-13T18:08:26.673076-08:00","updated_at":"2025-12-13T18:08:32.309879-08:00","closed_at":"2025-12-13T18:08:32.309879-08:00"}
{"id":"bd-2rfr","title":"GH#505: Add bd reset command to wipe database","description":"Users struggle to fully reset beads (local + remote). Need bd reset command with safety confirmation. Currently requires manual hook/dir removal. See: https://github.com/steveyegge/beads/issues/505","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-12-14T16:32:02.919494-08:00","updated_at":"2025-12-16T01:25:30.83613-08:00","closed_at":"2025-12-16T01:09:44.996918-08:00"}
{"id":"bd-379","title":"Implement `bd setup cursor` for Cursor IDE integration","description":"Create a `bd setup cursor` command that integrates Beads workflow into Cursor IDE via .cursorrules file. Unlike Claude Code (which has hooks), Cursor uses a static rules file to provide context to its AI.","status":"open","priority":3,"issue_type":"feature","created_at":"2025-11-11T23:32:22.170083-08:00","updated_at":"2025-11-11T23:32:22.170083-08:00"}
{"id":"bd-3852","title":"Add orphan detection migration","description":"Create migration to detect orphaned children in existing databases. Query: SELECT id FROM issues WHERE id LIKE '%.%' AND substr(id, 1, instr(id || '.', '.') - 1) NOT IN (SELECT id FROM issues). Log results, let user decide action (delete orphans or convert to top-level).","status":"open","priority":2,"issue_type":"task","created_at":"2025-11-04T12:32:30.727044-08:00","updated_at":"2025-11-04T12:32:30.727044-08:00"}
{"id":"bd-3ee1","title":"Sync sanitize incorrectly removes newly created issues","description":"## Problem\n\nThe sync sanitize process incorrectly identifies newly created issues as 'deleted issues resurrected by git merge' and removes them from the local JSONL file.\n\n## Reproduction\n\n1. Create a new issue: bd create --title='Test issue'\n2. Run bd sync\n3. Observe: New issue appears in sanitize removal list\n4. Issue is removed from local JSONL but preserved on beads-sync branch\n\n## Observed Behavior\n\nDuring sync, the sanitize step outputs:\n```\n‚Üí Sanitized JSONL: removed 738 deleted issue(s) that were resurrected by git merge\n  - bd-08ea  (newly created issue!)\n  - bd-tnsq  (newly created issue!)\n  ...\n```\n\nThe newly created issues get removed locally but remain on beads-sync branch.\n\n## Expected Behavior\n\nNewly created issues should NOT be removed by sanitize. The sanitize should only remove issues that:\n1. Were previously deleted (have tombstones or are in deletions manifest)\n2. Are being resurrected from old git history\n\n## Root Cause Investigation\n\nThe sanitize logic likely compares the local DB snapshot against some reference and incorrectly classifies new issues as 'resurrected deleted issues'. Possible causes:\n- Snapshot protection logic not accounting for new issues\n- Deletion manifest containing stale entries\n- Race condition between export and sanitize\n\n## Impact\n\n- New issues disappear from local JSONL after sync\n- Issues remain on beads-sync but cause confusion\n- Multi-agent workflows affected when agents can't see new issues locally\n- Requires manual intervention to recover\n\n## Files to Investigate\n\n- cmd/bd/sync.go - sanitize logic\n- cmd/bd/snapshot_manager.go - snapshot comparison\n- Deletion manifest handling\n\n## Acceptance Criteria\n\n- [ ] Newly created issues survive sync without being sanitized\n- [ ] Only truly deleted/resurrected issues are removed\n- [ ] Add test case for this scenario","status":"closed","priority":0,"issue_type":"bug","created_at":"2025-12-14T00:45:26.828547-08:00","updated_at":"2025-12-14T00:54:44.772671-08:00","closed_at":"2025-12-14T00:54:44.772671-08:00"}
{"id":"bd-3sz0","title":"Auto-repair stale merge driver configs with invalid placeholders","description":"Old bd versions (\u003c0.24.0) installed merge driver with invalid placeholders %L %R instead of %A %B. Add detection to bd doctor --fix: check if git config merge.beads.driver contains %L or %R, auto-repair to 'bd merge %A %O %A %B'. One-time migration for users who initialized with old versions.","status":"open","priority":2,"issue_type":"feature","created_at":"2025-11-21T23:16:10.762808-08:00","updated_at":"2025-11-21T23:16:28.892655-08:00","dependencies":[{"issue_id":"bd-3sz0","depends_on_id":"bd-tbz3","type":"parent-child","created_at":"2025-11-21T23:16:10.763612-08:00","created_by":"daemon"}]}
{"id":"bd-411u","title":"Document BEADS_DIR pattern for multi-agent workspaces (Gas Town)","description":"Gas Town and similar multi-agent systems need to configure separate beads databases per workspace/rig, distinct from any project-level beads.\n\n## Use Case\n\nIn Gas Town:\n- Each 'rig' (managed project) has multiple agents (polecats, refinery, witness)\n- All agents in a rig should share a single beads database at the rig level\n- This should be separate from any .beads/ the project itself uses\n- The BEADS_DIR env var enables this\n\n## Documentation Needed\n\n1. Add a section to docs explaining BEADS_DIR for multi-agent setups\n2. Example: setting BEADS_DIR in agent startup scripts/hooks\n3. Clarify interaction with project-level .beads/ (BEADS_DIR takes precedence)\n\n## Current Support\n\nAlready implemented in internal/beads/beads.go:FindDatabasePath():\n- BEADS_DIR env var is checked first (preferred)\n- BEADS_DB env var still supported (deprecated)\n- Falls back to .beads/ search in tree\n\nJust needs documentation for the multi-agent workspace pattern.","status":"open","priority":3,"issue_type":"task","created_at":"2025-12-15T22:08:22.158027-08:00","updated_at":"2025-12-15T22:08:22.158027-08:00"}
{"id":"bd-47tn","title":"Add bd daemon --stop-all command to kill all daemon processes","description":"Currently there's no easy way to stop all running bd daemon processes. Users must resort to pkill -f 'bd daemon' or similar shell commands.\n\nAdd a --stop-all flag to bd daemon that:\n1. Finds all running bd daemon processes (not just the current repo's daemon)\n2. Gracefully stops them all\n3. Reports how many were stopped\n\nThis is useful when:\n- Multiple daemons are running and causing race conditions\n- User wants a clean slate before running bd sync\n- Debugging daemon-related issues","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-12-13T06:34:45.080633-08:00","updated_at":"2025-12-16T01:25:30.837116-08:00","closed_at":"2025-12-14T17:33:03.057089-08:00"}
{"id":"bd-49kw","title":"Workaround for FastMCP outputSchema bug in Claude Code","description":"The beads MCP server (v0.23.1) successfully connects to Claude Code, but all tools fail to load with a schema validation error due to a bug in FastMCP 2.13.1.\n\nError: \"Invalid literal value, expected \\\"object\\\"\" in outputSchema.\n\nRoot Cause: FastMCP generates outputSchema with $ref at root level without \"type\": \"object\" for self-referential models (Issue).\n\nWorkaround: Use slash commands (/beads:ready) or wait for FastMCP fix.\n","status":"open","priority":1,"issue_type":"bug","created_at":"2025-11-20T18:55:39.041831-05:00","updated_at":"2025-11-20T18:55:39.041831-05:00"}
{"id":"bd-4ec8","title":"Widespread double JSON encoding bug in daemon mode RPC calls","description":"Multiple CLI commands had the same double JSON encoding bug found in bd-1048. All commands that called ResolveID via RPC used string(resp.Data) instead of properly unmarshaling the JSON response. This caused IDs to retain JSON quotes (\"bd-1048\" instead of bd-1048), which then got double-encoded when passed to subsequent RPC calls.\n\nAffected commands:\n- bd show (3 instances)\n- bd dep add/remove/tree (5 instances)\n- bd label add/remove/list (3 instances)\n- bd reopen (1 instance)\n\nRoot cause: resp.Data is json.RawMessage (already JSON-encoded), so string() conversion preserves quotes.\n\nFix: Replace all string(resp.Data) with json.Unmarshal(resp.Data, \u0026id) for proper deserialization.\n\nAll commands now tested and working correctly with daemon mode.","status":"open","priority":0,"issue_type":"bug","created_at":"2025-11-02T22:33:01.632691-08:00","updated_at":"2025-11-02T22:33:01.632691-08:00"}
{"id":"bd-4hn","title":"wish: list \u0026 ready show issues as hierarchy tree","description":"`bd ready` and `bd list` just show a flat list, and it's up to the reader to parse which ones are dependent or sub-issues of others. It would be much easier to understand if they were shown in a tree format","status":"open","priority":3,"issue_type":"task","created_at":"2025-12-08T06:38:24.016316945-07:00","updated_at":"2025-12-08T06:39:04.065882225-07:00"}
{"id":"bd-4q8","title":"bd cleanup --hard should skip tombstone creation for true permanent deletion","description":"## Problem\n\nWhen using bd cleanup --hard --older-than N --force, the command:\n1. Deletes closed issues older than N days (converting them to tombstones with NOW timestamp)\n2. Then tries to prune tombstones older than N days (finds none because they were just created)\n\nThis leaves the database bloated with fresh tombstones that will not be pruned.\n\n## Expected Behavior\n\nIn --hard mode, the deletion should be permanent without creating tombstones, since the user explicitly requested bypassing sync safety.\n\n## Workaround\n\nManually delete from database: sqlite3 .beads/beads.db 'DELETE FROM issues WHERE status=tombstone'\n\n## Fix Options\n\n1. In --hard mode, use a different delete path that does not create tombstones\n2. After deleting, immediately prune the just-created tombstones regardless of age\n3. Pass a skip_tombstone flag to the delete operation\n\nOption 1 is cleanest - --hard should mean permanent delete without tombstone.","status":"open","priority":1,"issue_type":"bug","created_at":"2025-12-16T01:33:36.580657-08:00","updated_at":"2025-12-16T01:33:36.580657-08:00"}
{"id":"bd-4qfb","title":"Improve bd doctor output formatting for better readability","description":"The current bd doctor output is a wall of text that's hard to process. Consider improvements like:\n- Grouping related checks into collapsible sections\n- Using color/bold for section headers\n- Showing only failures/warnings by default with --verbose for full output\n- Better visual hierarchy between major sections\n- Summary line at top (e.g., '24 checks passed, 0 warnings, 0 errors')","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-13T09:29:27.557578+11:00","updated_at":"2025-12-13T09:29:27.557578+11:00"}
{"id":"bd-4ri","title":"Fix TestFallbackToDirectModeEnablesFlush deadlock causing 10min test timeout","description":"## Problem\n\nTestFallbackToDirectModeEnablesFlush in direct_mode_test.go deadlocks for 9m59s before timing out, causing the entire test suite to take 10+ minutes instead of \u003c10 seconds.\n\n## Root Cause\n\nDatabase lock contention between test cleanup and flushToJSONL():\n- Test cleanup (line 36) tries to close DB via defer\n- flushToJSONL() (line 132) is still accessing DB\n- Results in deadlock: database/sql.(*DB).Close() waits for mutex while GetJSONLFileHash() holds it\n\n## Stack Trace Evidence\n\n```\ngoroutine 512 [sync.Mutex.Lock, 9 minutes]:\ndatabase/sql.(*DB).Close(0x14000643790)\n  .../database/sql/sql.go:927 +0x84\ngithub.com/steveyegge/beads/cmd/bd.TestFallbackToDirectModeEnablesFlush.func1()\n  .../direct_mode_test.go:36 +0xf4\n\nWhile goroutine running flushToJSONL() holds DB connection via GetJSONLFileHash()\n```\n\n## Impact\n\n- Test suite: 10+ minutes ‚Üí should be \u003c10 seconds\n- ALL other tests pass in ~4 seconds\n- This ONE test accounts for 99.9% of test runtime\n\n## Related\n\nThis is the EXACT same issue documented in MAIN_TEST_REFACTOR_NOTES.md for why main_test.go refactoring was deferred - global state manipulation + DB cleanup = deadlock.\n\n## Fix Approaches\n\n1. **Add proper cleanup sequencing** - stop flush goroutines BEFORE closing DB\n2. **Use test-specific DB lifecycle** - ensure flush completes before cleanup\n3. **Mock the flush mechanism** - avoid real DB for testing this code path  \n4. **Add explicit timeout handling** - fail fast with clear error instead of hanging\n\n## Files\n\n- cmd/bd/direct_mode_test.go:36-132\n- cmd/bd/autoflush.go:353 (validateJSONLIntegrity)\n- cmd/bd/autoflush.go:508 (flushToJSONLWithState)\n\n## Acceptance\n\n- Test passes without timeout\n- Test suite completes in \u003c10 seconds\n- No deadlock between cleanup and flush operations","status":"open","priority":1,"issue_type":"bug","created_at":"2025-11-21T20:09:00.794372-05:00","updated_at":"2025-11-21T20:09:00.794372-05:00"}
{"id":"bd-4u2b","title":"Make MCP compaction settings configurable (COMPACTION_THRESHOLD, PREVIEW_COUNT)","description":"Currently COMPACTION_THRESHOLD (20) and PREVIEW_COUNT (5) are hardcoded constants at the module level. This prevents users from tuning context engineering behavior.\n\n## Current State\n```python\nCOMPACTION_THRESHOLD = 20  # Compact results with more than 20 issues\nPREVIEW_COUNT = 5          # Show first 5 issues in preview\n```\n\n## Problems\n1. No way for MCP clients to request different preview sizes\n2. No way to disable compaction for debugging\n3. No way to adapt to different context window sizes\n4. Values are not documented in tool schema\n\n## Recommended Solution\nAdd environment variables or MCP tool parameters:\n- `BEADS_MCP_COMPACTION_THRESHOLD` env var (default: 20)\n- `BEADS_MCP_PREVIEW_COUNT` env var (default: 5)\n- Optional `compact_threshold` and `preview_size` parameters to list/ready tools\n\n## Implementation Notes\n- Keep current defaults for backward compatibility\n- Read from environment at server initialization\n- Document in CONTEXT_ENGINEERING.md\n- Add tests verifying env var behavior","status":"closed","priority":3,"issue_type":"task","created_at":"2025-12-14T14:24:34.037997-08:00","updated_at":"2025-12-14T14:40:48.79752-08:00","closed_at":"2025-12-14T14:40:48.79752-08:00","dependencies":[{"issue_id":"bd-4u2b","depends_on_id":"bd-otf4","type":"discovered-from","created_at":"2025-12-14T14:24:34.039165-08:00","created_by":"stevey"}]}
{"id":"bd-4uoc","title":"Code Review Followup Summary: PR #481 + PR #551","description":"## Merged PRs Summary\n\n### PR #551: Persist close_reason to issues table\n- ‚úÖ Merged successfully\n- ‚úÖ Bug fix: close_reason now persisted in database column (not just events table)\n- ‚úÖ Comprehensive test coverage added\n- ‚úÖ Handles reopen case (clearing close_reason)\n\n**Followup Issues Filed:**\n- bd-lxzx: Document close_reason in JSONL export format\n- bd-077e: Update CLI documentation for close_reason field\n\n---\n\n### PR #481: Context Engineering Optimizations (80-90% context reduction)\n- ‚úÖ Merged successfully  \n- ‚úÖ Lazy tool discovery: discover_tools() + get_tool_info()\n- ‚úÖ Minimal issue models: IssueMinimal (~80% smaller than full Issue)\n- ‚úÖ Result compaction: Auto-compacts results \u003e20 items\n- ‚úÖ All 28 tests passing\n- ‚ö†Ô∏è Breaking change: ready() and list() return type changed\n\n**Followup Issues Filed:**\n- bd-b318: Add integration tests for CompactedResult\n- bd-4u2b: Make compaction settings configurable (THRESHOLD, PREVIEW_COUNT)\n- bd-2kf8: Document CompactedResult response format in CONTEXT_ENGINEERING.md\n- bd-pdr2: Document backwards compatibility considerations\n\n---\n\n## Overall Assessment\n\nBoth PRs are production-ready with solid implementations. All critical functionality works and tests pass. Followup issues focus on:\n1. Documentation improvements (5 issues)\n2. Integration test coverage (1 issue)\n3. Configuration flexibility (1 issue)\n4. Backwards compatibility guidance (1 issue)\n\nNo critical bugs or design issues found.\n\n## Review Completed By\nCode review process completed. Issues auto-created for tracking improvements.","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-14T14:25:59.214886-08:00","updated_at":"2025-12-14T14:25:59.214886-08:00","dependencies":[{"issue_id":"bd-4uoc","depends_on_id":"bd-otf4","type":"discovered-from","created_at":"2025-12-14T14:25:59.216884-08:00","created_by":"stevey"},{"issue_id":"bd-4uoc","depends_on_id":"bd-z86n","type":"discovered-from","created_at":"2025-12-14T14:25:59.217296-08:00","created_by":"stevey"}]}
{"id":"bd-55sb","title":"Stealth mode global gitignore should use absolute project path","description":"**GitHub Issue:** #538\n\n**Problem:**\n`bd init --stealth` adds `.beads/` to the global gitignore, which ignores ALL `.beads/` folders across all repositories. Users who want stealth mode in one project but open beads usage in others are blocked.\n\n**Solution:**\nChange stealth mode to use absolute paths instead of generic patterns:\n\n**Before (current):**\n```\n# Beads stealth mode configuration (added by bd init --stealth)\n.beads/\n.claude/settings.local.json\n```\n\n**After (proposed):**\n```\n# Beads stealth mode: /Users/foo/work-project (added by bd init --stealth)\n/Users/foo/work-project/.beads/\n/Users/foo/work-project/.claude/settings.local.json\n```\n\n**Implementation:**\n1. Modify `setupGlobalGitIgnore()` in `cmd/bd/init.go`\n2. Get current working directory (absolute path)\n3. Use absolute path patterns instead of generic ones\n4. Update comment to show which project the entry is for\n\n**Tradeoffs:**\n- If project directory moves, gitignore entry becomes stale (acceptable - user can re-run `bd init --stealth`)\n- Multiple stealth projects = multiple entries (works correctly)\n\n**Testing:**\n- Verify absolute path is added to global gitignore\n- Verify other projects' .beads/ folders are NOT ignored\n- Test with existing global gitignore file\n- Test creating new global gitignore file","status":"closed","priority":2,"issue_type":"bug","created_at":"2025-12-13T10:55:22.594278-08:00","updated_at":"2025-12-13T10:57:38.0241-08:00","closed_at":"2025-12-13T10:57:38.0241-08:00"}
{"id":"bd-56x","title":"Review PR #514: fix plugin install docs","description":"Review and merge PR #514 from aspiers. This PR fixes incorrect docs for installing Claude Code plugin from source in docs/PLUGIN.md. Clarifies shell vs Claude Code commands and fixes the . vs ./beads argument issue. URL: https://github.com/anthropics/beads/pull/514","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-13T08:15:16.865354+11:00","updated_at":"2025-12-13T07:07:19.729213-08:00","closed_at":"2025-12-13T07:07:19.729213-08:00"}
{"id":"bd-581b80b3","title":"bd find-duplicates - AI-powered duplicate detection","description":"Find semantically duplicate issues.\n\nApproaches:\n1. Mechanical: Exact title/description matching\n2. Embeddings: Cosine similarity (cheap, scalable)\n3. AI: LLM-based semantic comparison (expensive, accurate)\n\nUses embeddings by default for \u003e100 issues.\n\nFiles: cmd/bd/find_duplicates.go (new)","status":"open","priority":1,"issue_type":"task","created_at":"2025-10-29T20:49:49.126801-07:00","updated_at":"2025-10-30T17:12:58.218673-07:00"}
{"id":"bd-59er","title":"Add --lock-timeout global flag","description":"Add new global flag to control SQLite busy_timeout.\n\n## Implementation\n1. Add to cmd/bd/main.go:\n   - `lockTimeout time.Duration` global variable  \n   - Register flag: `--lock-timeout=\u003cduration\u003e` (default 30s)\n\n2. Add config support in internal/config/config.go:\n   - `v.SetDefault(\"lock-timeout\", \"30s\")`\n   - Read from config.yaml if not set via flag\n\n3. Pass timeout to sqlite.New() - see next task\n\n## Acceptance Criteria\n- `bd --lock-timeout=0 list` fails immediately if DB is locked\n- `bd --lock-timeout=100ms list` waits max 100ms\n- Config file setting works: `lock-timeout: 100ms`\n- Default remains 30s for backward compatibility\n\nPart of bd-olc1","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-13T17:54:36.277179-08:00","updated_at":"2025-12-13T18:05:19.367765-08:00","closed_at":"2025-12-13T18:05:19.367765-08:00"}
{"id":"bd-5a90","title":"Test parent issue","description":"","status":"closed","priority":3,"issue_type":"task","created_at":"2025-11-02T11:50:35.85367-08:00","updated_at":"2025-12-13T23:29:56.878674-08:00","closed_at":"2025-12-13T23:29:56.878674-08:00"}
{"id":"bd-5b6e","title":"Add tests for helper functions (GetDirtyIssueHash, GetAllDependencyRecords, export hashes)","description":"Several utility functions have 0% coverage:\n- GetDirtyIssueHash (dirty.go)\n- GetAllDependencyRecords (dependencies.go)\n- GetExportHash, SetExportHash, ClearAllExportHashes (hash.go)\n\nThese are lower priority but should have basic coverage.","status":"open","priority":4,"issue_type":"task","created_at":"2025-11-01T22:40:58.989976-07:00","updated_at":"2025-11-01T22:40:58.989976-07:00"}
{"id":"bd-5ibn","title":"Latency test 1","description":"","notes":"Resetting stale in_progress status from old executor run (yesterday)","status":"closed","priority":3,"issue_type":"task","created_at":"2025-11-20T12:16:30.703754-05:00","updated_at":"2025-12-13T23:29:56.878439-08:00","closed_at":"2025-12-13T23:29:56.878439-08:00"}
{"id":"bd-5qim","title":"Optimize GetReadyWork performance - 752ms on 10K database (target: \u003c50ms)","description":"","notes":"# Performance Analysis (10K Issue Database)\n\nAnalyzed using CPU profiles from benchmark suite on Apple M2 Pro.\n\n## Operation Performance\n\n| Operation                        | Time    | Allocations | Memory |\n|----------------------------------|---------|-------------|--------|\n| bd ready (GetReadyWork)          | ~752ms  | 167,466     | 16MB   |\n| bd list (SearchIssues no filter) | ~11.6ms | 89,214      | 5.8MB  |\n| bd list (SearchIssues filtered)  | ~9.2ms  | 62,365      | 3.5MB  |\n| bd create (CreateIssue)          | ~2.6ms  | 146         | 8.6KB  |\n| bd update (UpdateIssue)          | ~0.32ms | 364         | 15KB   |\n| bd close (UpdateIssue)           | ~0.32ms | 364         | 15KB   |\n\n**Target: \u003c50ms for all operations on 10K database**\n\n**Current issue: GetReadyWork is 15x over target (752ms vs 50ms)**\n\n## Root Cause\n\nGetReadyWork (internal/storage/sqlite/ready.go:90-128) uses recursive CTE to propagate blocking:\n- 65x slower than SearchIssues\n- Recalculates entire blocked issue tree on every call\n- Algorithm:\n  1. Find directly blocked issues via 'blocks' dependencies\n  2. Recursively propagate blockage to descendants (max depth: 50)\n  3. Exclude all blocked issues from results\n\n## CPU Profile Analysis\n\n- Database syscalls (pthread_cond_signal, syscall6): ~75%\n- SQLite engine overhead: inherent to recursive CTE\n- Application code (query construction): \u003c1%\n\n**Bottleneck is the recursive CTE query execution, not application code.**\n\n## Optimization Recommendations\n\n### High Impact (Likely to achieve \u003c50ms target)\n\n1. **Cache blocked issue calculation**\n   - Add `blocked_issues` table updated on dependency changes\n   - Trade write complexity for read speed (ready called \u003e\u003e dependency changes)\n   - Eliminates recursive CTE on every read\n\n2. **Add/verify database indexes**\n   ```sql\n   CREATE INDEX IF NOT EXISTS idx_dependencies_blocked \n     ON dependencies(issue_id, type, depends_on_id);\n   CREATE INDEX IF NOT EXISTS idx_issues_status \n     ON issues(status);\n   ```\n\n### Medium Impact\n\n3. **Reduce allocations** (167K allocations for GetReadyWork)\n   - Profile `scanIssues()` for object pooling opportunities\n   - Reuse slice capacity for repeated calls\n\n### Low Impact (Not recommended)\n- Query optimization for CRUD operations (already \u003c3ms)\n- Connection pooling tuning (not showing in profiles)\n\n## Verification\n\nRun benchmarks to validate optimization:\n```bash\nmake bench-quick\ngo tool pprof -http=:8080 internal/storage/sqlite/bench-cpu-*.prof\n```\n\nProfile files automatically generated in `internal/storage/sqlite/`.","status":"open","priority":0,"issue_type":"bug","created_at":"2025-11-14T09:02:46.507526-08:00","updated_at":"2025-11-14T09:03:44.073236-08:00"}
{"id":"bd-5we","title":"Use RAM disk for Windows CI tests","description":"Windows CI tests time out due to slow filesystem I/O. Even with splitting into parallel jobs, each package set takes \u003e30 minutes.\n\nImplement a RAM disk solution using ImDisk or similar on Windows GitHub Actions runners to speed up tests.\n\nReferences:\n- https://github.com/actions/runner-images/issues/intlharry has examples\n- ImDisk can create RAM disks on Windows\n- Alternative: use D: drive which may be faster on some runners","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-04T20:30:23.877831-08:00","updated_at":"2025-12-13T12:54:00.045208828-05:00","closed_at":"2025-12-13T07:28:44.636222-08:00"}
{"id":"bd-6fe4622f","title":"Remove unreachable utility functions","description":"Several small utility functions are unreachable:\n\nFiles to clean:\n1. `internal/storage/sqlite/hash.go` - `computeIssueContentHash` (line 17)\n   - Check if entire file can be deleted if only contains this function\n\n2. `internal/config/config.go` - `FileUsed` (line 151)\n   - Delete unused config helper\n\n3. `cmd/bd/git_sync_test.go` - `verifyIssueOpen` (line 300)\n   - Delete dead test helper\n\n4. `internal/compact/haiku.go` - `HaikuClient.SummarizeTier2` (line 81)\n   - Tier 2 summarization not implemented\n   - Options: implement feature OR delete method\n\nImpact: Removes 50-100 LOC depending on decisions","acceptance_criteria":"- Remove unreachable functions\n- If entire files can be deleted (like hash.go), delete them\n- For SummarizeTier2: decide to implement or delete, document decision\n- All tests pass: `go test ./...`\n- Verify no callers exist for each function","status":"open","priority":2,"issue_type":"task","created_at":"2025-10-28T16:20:02.434573-07:00","updated_at":"2025-10-30T17:12:58.224957-07:00"}
{"id":"bd-6pni","title":"bd doctor --fix should auto-fix prefix mismatch errors","description":"When bd doctor --fix encounters a prefix mismatch during DB-JSONL sync fix, it fails without offering to use --rename-on-import.\n\n**Current behavior:**\n```\nFixing DB-JSONL Sync...\n‚Üí Importing from JSONL...\nError importing: import failed: exit status 1\nImport failed: prefix mismatch detected: database uses 'bd-' but found issues with prefixes: [beads- (2 issues) test- (10 issues)]\n```\n\n**Expected behavior:**\n- Detect that the mismatched prefixes are all tombstones\n- Auto-apply --rename-on-import since tombstones with wrong prefixes are pollution\n- Or prompt: 'Found 21 issues with wrong prefixes (all tombstones). Remove them? [Y/n]'\n\n**Context:** Prefix pollution typically comes from contributor PRs that used different test prefixes. These are always safe to remove when they're tombstones.","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-12-15T17:28:45.508654-08:00","updated_at":"2025-12-16T00:54:56.458264-08:00","closed_at":"2025-12-16T00:54:56.458264-08:00"}
{"id":"bd-6rl","title":"Merge3Way public API does not expose TTL parameter","description":"The public Merge3Way() function in merge.go does not allow callers to configure the tombstone TTL. It hard-codes the default via merge3WayWithTTL(). While merge3WayWithTTL() exists, it is unexported (lowercase). This means the CLI and tests cannot configure TTL at merge time. Use cases: testing with different TTL values, per-repository TTL configuration, debugging with short TTL, supporting --ttl flag in bd merge command (mentioned in design doc bd-zvg). Recommendation: Export Merge3WayWithTTL (rename to uppercase). Files: internal/merge/merge.go:77, 292-298","status":"open","priority":3,"issue_type":"feature","created_at":"2025-12-05T16:36:15.756814-08:00","updated_at":"2025-12-05T16:36:15.756814-08:00"}
{"id":"bd-6sm6","title":"Improve test coverage for internal/export (37.1% ‚Üí 60%)","description":"The export package has only 37.1% test coverage. Export functionality needs good coverage to ensure data integrity.\n\nCurrent coverage: 37.1%\nTarget coverage: 60%","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-13T20:43:06.802277-08:00","updated_at":"2025-12-13T21:01:19.08088-08:00"}
{"id":"bd-6xfz","title":"GH#517: Fix Claude setting wrong priority syntax on new install","description":"Claude uses 'medium' instead of P2/2 for priority, causing infinite error loops. bd prime hook or docs not clear enough. See: https://github.com/steveyegge/beads/issues/517","status":"closed","priority":1,"issue_type":"bug","created_at":"2025-12-14T16:31:55.740197-08:00","updated_at":"2025-12-16T01:25:30.840256-08:00","closed_at":"2025-12-16T01:08:05.911031-08:00"}
{"id":"bd-77gm","title":"Import reports misleading '0 created, 0 updated' when actually importing all issues","description":"When running 'bd import' on a fresh database (no existing issues), the command reports 'Import complete: 0 created, 0 updated' even though it successfully imported all issues from the JSONL file.\n\n**Steps to reproduce:**\n1. Delete .beads/beads.db\n2. Run: bd import .beads/issues.jsonl\n3. Observe output: 'Import complete: 0 created, 0 updated'\n4. Run: bd list\n5. Confirm: All issues are actually present in the database\n\n**Expected behavior:**\nReport the actual number of issues imported, e.g., 'Import complete: 523 created, 0 updated'\n\n**Actual behavior:**\n'Import complete: 0 created, 0 updated' (misleading - makes user think import failed)\n\n**Impact:**\n- Users think import failed when it succeeded\n- Confusing during database sync operations (e.g., after git pull)\n- Makes debugging harder (can't tell if import actually worked)\n\n**Context:**\nDiscovered during VC session when syncing database after git pull. The misleading message caused confusion about whether the database was properly synced with the canonical JSONL file.","status":"open","priority":2,"issue_type":"bug","created_at":"2025-11-09T16:20:13.191156-08:00","updated_at":"2025-11-09T16:20:13.191156-08:00"}
{"id":"bd-7di","title":"worktree: any bd command is slow","description":"in a git worktree any bd command is slow, with a 2-3s pause before any results are shown. The identical command with `--no-daemon` is near instant.","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-05T15:33:42.924618693-07:00","updated_at":"2025-12-05T15:33:42.924618693-07:00"}
{"id":"bd-7e7ddffa.1","title":"bd resolve-conflicts - Git merge conflict resolver","description":"Automatically resolve JSONL merge conflicts.\n\nModes:\n- Mechanical: ID remapping (no AI)\n- AI-assisted: Smart merge/keep decisions\n- Interactive: Review each conflict\n\nHandles \u003c\u003c\u003c\u003c\u003c\u003c\u003c conflict markers in .beads/beads.jsonl\n\nFiles: cmd/bd/resolve_conflicts.go (new)","status":"open","priority":1,"issue_type":"task","created_at":"2025-10-28T14:48:30.083642-07:00","updated_at":"2025-10-30T17:12:58.220145-07:00"}
{"id":"bd-7m16","title":"GH#519: bd sync fails when sync.branch is currently checked-out branch","description":"bd sync tries to create worktree for sync.branch even when already on that branch. Should commit directly instead. See GitHub issue #519.","status":"open","priority":2,"issue_type":"bug","created_at":"2025-12-16T01:03:36.613211-08:00","updated_at":"2025-12-16T01:03:36.613211-08:00"}
{"id":"bd-7r4l","title":"GH#488: Support claude.local.md for local-only config","description":"Allow CLAUDE.local.md for testing bd without committing to repo or overriding shared CLAUDE.md. Not every repo wants committed AI config. See: https://github.com/steveyegge/beads/issues/488","status":"in_progress","priority":2,"issue_type":"feature","created_at":"2025-12-14T16:32:19.944847-08:00","updated_at":"2025-12-14T16:52:49.800832-08:00"}
{"id":"bd-7yg","title":"Git merge driver uses invalid placeholders (%L, %R instead of %A, %B)","description":"## Problem\n\nThe beads git merge driver is configured with invalid Git placeholders:\n\n```\ngit config merge.beads.driver \"bd merge %A %O %L %R\"\n```\n\nGit doesn't recognize `%L` or `%R` as valid merge driver placeholders. The valid placeholders are:\n- `%O` = base (common ancestor)\n- `%A` = current version (ours)\n- `%B` = other version (theirs)\n\n## Impact\n\n- Affects ALL users when they have `.beads/beads.jsonl` merge conflicts\n- Automatic JSONL merge fails with error: \"error reading left file: failed to open file: open 7: no such file or directory\"\n- Users must manually resolve conflicts instead of getting automatic merge\n\n## Root Cause\n\nThe `bd init` command (or wherever the merge driver is configured) is using non-standard placeholders. When Git encounters `%L` and `%R`, it either passes them literally or interprets them incorrectly.\n\n## Fix\n\nUpdate the merge driver configuration to:\n```\ngit config merge.beads.driver \"bd merge %A %O %A %B\"\n```\n\nWhere:\n- 1st `%A` = output file (current file, will be overwritten)\n- `%O` = base (common ancestor)\n- 2nd `%A` = left/current version\n- `%B` = right/other version\n\n## Action Items\n\n1. Fix `bd init` (or equivalent setup command) to use correct placeholders\n2. Add migration/warning for existing users with misconfigured merge driver\n3. Update documentation with correct merge driver setup\n4. Consider adding validation when `bd init` is run","status":"open","priority":1,"issue_type":"bug","created_at":"2025-11-21T19:51:55.747608-05:00","updated_at":"2025-11-21T19:51:55.747608-05:00"}
{"id":"bd-83xx","title":"bd cleanup fails with CHECK constraint on status/closed_at mismatch","description":"## Problem\n\nRunning `bd cleanup --force` fails with:\n\n```\nError: failed to create tombstone for bd-okh: sqlite3: constraint failed: CHECK constraint failed: (status = 'closed') = (closed_at IS NOT NULL)\n```\n\n## Root Cause\n\nThe database has a CHECK constraint ensuring closed issues have `closed_at` set and non-closed issues don't. When `bd cleanup` tries to convert a closed issue to a tombstone, this constraint fails if:\n1. The issue has status='closed' but closed_at is NULL, OR\n2. The issue is being converted but the tombstone creation doesn't properly handle the closed_at field\n\n## Impact\n\n- `bd cleanup --force` cannot complete\n- 722 closed issues cannot be cleaned up\n- Blocks routine maintenance\n\n## Investigation Needed\n\n1. Check the bd-okh record in the database:\n   ```sql\n   SELECT id, status, closed_at, deleted_at FROM issues WHERE id = 'bd-okh';\n   ```\n2. Determine if this is data corruption or a bug in tombstone creation\n\n## Proposed Solutions\n\n1. **If data corruption**: Add a `bd doctor --fix` check that repairs status/closed_at mismatches\n2. **If code bug**: Fix the tombstone creation to properly handle the constraint\n\n## Files to Investigate\n\n- `internal/storage/sqlite/sqlite.go` - DeleteIssue / tombstone creation\n- Schema CHECK constraint definition\n\n## Acceptance Criteria\n\n- [ ] Identify root cause (data vs code bug)\n- [ ] `bd cleanup --force` completes successfully\n- [ ] `bd doctor` detects status/closed_at mismatches","status":"closed","priority":1,"issue_type":"bug","created_at":"2025-12-13T23:49:54.012806-08:00","updated_at":"2025-12-16T01:25:30.841139-08:00","closed_at":"2025-12-14T17:30:05.427749-08:00","deleted_at":"2025-12-14T00:25:57.309821-08:00","deleted_by":"git-history-backfill","delete_reason":"recovered from git history (pruned from manifest)","original_type":"bug"}
{"id":"bd-89f89fc0","title":"Remove unreachable RPC methods","description":"Several RPC server and client methods are unreachable and should be removed:\n\nServer methods (internal/rpc/server.go):\n- `Server.GetLastImportTime` (line 2116)\n- `Server.SetLastImportTime` (line 2123)\n- `Server.findJSONLPath` (line 2255)\n\nClient methods (internal/rpc/client.go):\n- `Client.Import` (line 311) - RPC import not used (daemon uses autoimport)\n\nEvidence:\n```bash\ngo run golang.org/x/tools/cmd/deadcode@latest -test ./...\n```\n\nImpact: Removes ~80 LOC of unused RPC code","acceptance_criteria":"- Remove the 4 unreachable methods (~80 LOC total)\n- Verify no callers: `grep -r \"GetLastImportTime\\|SetLastImportTime\\|findJSONLPath\" .`\n- All tests pass: `go test ./internal/rpc/...`\n- Daemon functionality works: test daemon start/stop/operations","status":"open","priority":2,"issue_type":"task","created_at":"2025-10-28T16:20:02.432202-07:00","updated_at":"2025-10-30T17:12:58.222655-07:00"}
{"id":"bd-8g8","title":"Fix G304 potential file inclusion in cmd/bd/tips.go:259","description":"Linting issue: G304: Potential file inclusion via variable (gosec) at cmd/bd/tips.go:259:18. Error: if data, err := os.ReadFile(settingsPath); err == nil {","status":"open","priority":0,"issue_type":"bug","created_at":"2025-12-07T15:34:57.189730843-07:00","updated_at":"2025-12-07T15:34:57.189730843-07:00"}
{"id":"bd-8v5o","title":"bd doctor --fix hydrates issues that remain in deletions manifest, causing perpetual skip warnings","description":"When bd doctor --fix hydrates issues from git history, it doesn't remove them from the deletions manifest. This causes a conflict where:\n1. Issue exists in database as 'open'\n2. Issue also exists in deletions manifest\n3. Every sync reports 'Skipping bd-xxx (in deletions manifest)'\n4. Issue is 'Protected from incorrect sanitization'\n\n**Reproduction:**\n1. Run bd doctor --fix (which hydrates issues from git history)\n2. Run bd sync\n3. Observe conflicting messages about protected issues being skipped\n\n**Affected issues in this session:**\nbd-eyto, bd-6rl, bd-y2v, bd-abjw, bd-a0cp, bd-mql4, bd-nl2\n\n**Expected behavior:**\nWhen hydrating an issue, also remove it from the deletions manifest to prevent conflict.\n\n**Workaround:** Manually remove conflicting IDs from deletions.jsonl","status":"closed","priority":1,"issue_type":"bug","created_at":"2025-12-15T17:28:40.060713-08:00","updated_at":"2025-12-16T00:41:33.165408-08:00","closed_at":"2025-12-16T00:41:33.165408-08:00"}
{"id":"bd-8wa","title":"Code Review Sweep: thorough","description":"Perform thorough code review sweep based on accumulated activity.\n\n**AI Reasoning:**\nSignificant code volume added (150,273 lines) across multiple critical areas, including cmd/bd, internal/storage/sqlite, and internal/rpc. High file change count (616) indicates substantial refactoring or new functionality. The metrics suggest potential for subtle architectural or implementation issues that warrant review.\n\n**Scope:** thorough\n**Target Areas:** cmd/bd, internal/storage/sqlite, internal/rpc\n**Estimated Files:** 12\n**Estimated Cost:** $5\n\n**Task:**\nReview files for non-obvious issues that agents miss during focused work:\n- Inefficiencies (algorithmic, resource usage)\n- Subtle bugs (race conditions, off-by-one, copy-paste)\n- Poor patterns (coupling, complexity, duplication)\n- Missing best practices (error handling, docs, tests)\n- Unnamed anti-patterns\n\nFile discovered issues with detailed reasoning and suggestions.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-11-21T10:25:37.081296-05:00","updated_at":"2025-12-13T23:33:16.521045-08:00","closed_at":"2025-12-13T23:33:16.521045-08:00"}
{"id":"bd-90v","title":"bd prime: AI context loading and Claude Code integration","description":"Implement `bd prime` command and Claude Code hooks for context recovery. Hooks work with BOTH MCP server and CLI approaches - they solve the context memory problem (keeping bd workflow fresh after compaction) not the tool access problem (MCP vs CLI).","status":"open","priority":2,"issue_type":"epic","created_at":"2025-11-11T23:31:12.119012-08:00","updated_at":"2025-11-12T00:11:07.743189-08:00"}
{"id":"bd-98c4e1fa.1","title":"Update AGENTS.md with event-driven mode","description":"Document BEADS_DAEMON_MODE env var. Explain opt-in during Phase 1. Add troubleshooting for watcher failures.","status":"open","priority":2,"issue_type":"task","created_at":"2025-10-29T23:05:13.986452-07:00","updated_at":"2025-10-31T20:36:49.381832-07:00"}
{"id":"bd-9cdc","title":"Update docs for import bug fix","description":"Update AGENTS.md, README.md, TROUBLESHOOTING.md with import.orphan_handling config documentation. Document resurrection behavior, tombstones, config modes. Add troubleshooting section for import failures with deleted parents.","status":"open","priority":2,"issue_type":"task","created_at":"2025-11-04T12:32:30.770415-08:00","updated_at":"2025-11-04T12:32:30.770415-08:00"}
{"id":"bd-9msn","title":"Add monitoring and alerting","description":"Observability for production Agent Mail server.\n\nAcceptance Criteria:\n- Health check endpoint (/health)\n- Prometheus metrics export\n- Grafana dashboard\n- Alerts for server downtime\n- Alerts for high error rate\n- Log aggregation config\n\nFile: deployment/agent-mail/monitoring/","status":"closed","priority":3,"issue_type":"task","created_at":"2025-11-07T22:43:43.354117-08:00","updated_at":"2025-12-14T00:32:11.050086-08:00","closed_at":"2025-12-13T23:30:58.72719-08:00","dependencies":[{"issue_id":"bd-9msn","depends_on_id":"bd-z3s3","type":"blocks","created_at":"2025-11-07T23:04:28.050074-08:00","created_by":"daemon"}]}
{"id":"bd-9w3s","title":"Improve test coverage for internal/lockfile (42.0% ‚Üí 60%)","description":"The lockfile package has only 42.0% test coverage. Lock file handling is critical for preventing data corruption in concurrent scenarios.\n\nCurrent coverage: 42.0%\nTarget coverage: 60%","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-13T20:43:08.47488-08:00","updated_at":"2025-12-14T15:20:51.463282-08:00","closed_at":"2025-12-14T15:20:51.463282-08:00"}
{"id":"bd-a0cp","title":"Consider using types.Status in merge package for type safety","description":"The merge package uses string for status comparison (e.g., result.Status == closed, issue.Status == StatusTombstone). The types package defines Status as a type alias with validation. While the merge package needs its own Issue struct for JSONL flexibility, it could import and use types.Status for constants to get compile-time type checking. Current code: if left == closed || right == closed. Could be: if left == string(types.StatusClosed). This is low priority since string comparison works correctly. Files: internal/merge/merge.go:44, 488, 501-521","status":"open","priority":4,"issue_type":"task","created_at":"2025-12-05T16:37:10.690424-08:00","updated_at":"2025-12-05T16:37:10.690424-08:00"}
{"id":"bd-a15d","title":"Add test files for internal/storage","description":"The internal/storage package has no test files at all. This package provides the storage interface abstraction.\n\nCurrent coverage: N/A (no test files)\nTarget: Add basic interface tests","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-13T20:43:11.363017-08:00","updated_at":"2025-12-13T21:01:20.925779-08:00"}
{"id":"bd-abjw","title":"Consider consolidating config.yaml parsing into shared utility","description":"Multiple places parse config.yaml with custom structs:\n\n1. **autoimport.go:148** - `localConfig{SyncBranch}`\n2. **main.go:310** - strings.Contains for no-db (fragile, see bd-r6k2)\n3. **doctor.go:863** - strings.Contains for no-db (fragile, see bd-r6k2)\n4. **internal/config/config.go** - Uses viper (but caches at startup, problematic for tests)\n\nConsider creating a shared utility in `internal/configfile/` or extending the viper config:\n\n```go\n// internal/configfile/yaml.go\ntype YAMLConfig struct {\n    SyncBranch string `yaml:\"sync-branch\"`\n    NoDb       bool   `yaml:\"no-db\"`\n    IssuePrefix string `yaml:\"issue-prefix\"`\n    Author     string `yaml:\"author\"`\n}\n\nfunc LoadYAML(beadsDir string) (*YAMLConfig, error) {\n    // Parse config.yaml with proper YAML library\n}\n```\n\nBenefits:\n- Single source of truth for config.yaml structure\n- Proper YAML parsing everywhere\n- Easier to add new config fields\n\nTrade-off: May add complexity for simple one-off reads.","status":"open","priority":4,"issue_type":"task","created_at":"2025-12-07T02:03:26.067311-08:00","updated_at":"2025-12-07T02:03:26.067311-08:00"}
{"id":"bd-admx","title":"Perpetual 'JSONL file hash mismatch detected (bd-160)' warning","description":"After cleanup operations, every bd command shows:\n```\n‚ö†Ô∏è  WARNING: JSONL file hash mismatch detected (bd-160)\n  This indicates JSONL and export_hashes are out of sync.\n  Clearing export_hashes to force full re-export.\n```\n\nThe warning appears repeatedly even after the hash is supposedly cleared. This suggests either:\n1. The clear isn't persisting\n2. Something keeps causing the mismatch\n3. The detection logic has a bug\n\n**Impact:** Warning fatigue - users ignore it, may miss real issues.\n\n**Expected behavior:** After clearing export_hashes once, subsequent operations should not show the warning unless there's a new mismatch.","status":"closed","priority":2,"issue_type":"bug","created_at":"2025-12-15T17:28:56.361302-08:00","updated_at":"2025-12-16T00:54:56.46055-08:00","closed_at":"2025-12-16T00:54:56.46055-08:00"}
{"id":"bd-aec5439f","title":"Update LINTING.md with current baseline","description":"After cleanup, document the remaining acceptable baseline in LINTING.md so we can track regression.","status":"open","priority":2,"issue_type":"task","created_at":"2025-10-27T18:53:10.38679-07:00","updated_at":"2025-10-30T17:12:58.194901-07:00"}
{"id":"bd-au0","title":"Command Set Standardization \u0026 Flag Consistency","description":"Comprehensive improvements to bd command set based on 2025 audit findings.\n\n## Background\nSee docs/command-audit-2025.md for detailed analysis.\n\n## Goals\n1. Standardize flag naming and behavior across all commands\n2. Add missing flags for feature parity\n3. Fix naming confusion\n4. Improve consistency in JSON output\n\n## Success Criteria\n- All mutating commands support --dry-run (no --preview variants)\n- bd update supports label operations\n- bd search has filter parity with bd list\n- Priority flags accept both int and P0-P4 format everywhere\n- JSON output is consistent across all commands","status":"open","priority":2,"issue_type":"epic","created_at":"2025-11-21T21:05:55.672749-05:00","updated_at":"2025-11-21T21:05:55.672749-05:00"}
{"id":"bd-au0.10","title":"Add global verbosity flags (--verbose, --quiet)","description":"Add consistent verbosity controls across all commands.\n\n**Current state:**\n- bd init has --quiet flag\n- No other commands have verbosity controls\n- Debug output controlled by BD_VERBOSE env var\n\n**Proposal:**\nAdd persistent flags:\n- --verbose / -v: Enable debug output\n- --quiet / -q: Suppress non-essential output\n\n**Implementation:**\n- Add to rootCmd.PersistentFlags()\n- Replace BD_VERBOSE checks with flag checks\n- Standardize output levels:\n  * Quiet: Errors only\n  * Normal: Errors + success messages\n  * Verbose: Errors + success + debug info\n\n**Files to modify:**\n- cmd/bd/main.go (add flags)\n- internal/debug/debug.go (respect flags)\n- Update all commands to respect quiet mode\n\n**Testing:**\n- Verify --verbose shows debug output\n- Verify --quiet suppresses normal output\n- Ensure errors always show regardless of mode","status":"open","priority":3,"issue_type":"task","created_at":"2025-11-21T21:08:21.600209-05:00","updated_at":"2025-11-21T21:08:21.600209-05:00","dependencies":[{"issue_id":"bd-au0.10","depends_on_id":"bd-au0","type":"parent-child","created_at":"2025-11-21T21:08:21.602557-05:00","created_by":"daemon"}]}
{"id":"bd-au0.5","title":"Add date and priority filters to bd search","description":"Add filter parity with bd list for consistent querying.\n\n**Missing filters to add:**\n- --priority, --priority-min, --priority-max\n- --created-after, --created-before\n- --updated-after, --updated-before\n- --closed-after, --closed-before\n- --empty-description, --no-assignee, --no-labels\n- --desc-contains, --notes-contains\n\n**Files to modify:**\n- cmd/bd/search.go\n- internal/rpc/protocol.go (SearchArgs)\n- internal/storage/storage.go (Search method)\n\n**Testing:**\n- All filter combinations\n- Date format parsing\n- Daemon and direct mode","status":"open","priority":1,"issue_type":"task","created_at":"2025-11-21T21:07:05.496726-05:00","updated_at":"2025-11-21T21:07:05.496726-05:00","dependencies":[{"issue_id":"bd-au0.5","depends_on_id":"bd-au0","type":"parent-child","created_at":"2025-11-21T21:07:05.497762-05:00","created_by":"daemon"}]}
{"id":"bd-au0.6","title":"Add comprehensive filters to bd export","description":"Enhance bd export with filtering options for selective exports.\n\n**Currently only has:**\n- --status\n\n**Add filters:**\n- --label, --label-any\n- --assignee\n- --type\n- --priority, --priority-min, --priority-max\n- --created-after, --created-before\n- --updated-after, --updated-before\n\n**Use case:**\n- Export only open issues: bd export --status open\n- Export high-priority bugs: bd export --type bug --priority-max 1\n- Export recent issues: bd export --created-after 2025-01-01\n\n**Files to modify:**\n- cmd/bd/export.go\n- Reuse filter logic from list.go","status":"open","priority":1,"issue_type":"task","created_at":"2025-11-21T21:07:19.431307-05:00","updated_at":"2025-11-21T21:07:19.431307-05:00","dependencies":[{"issue_id":"bd-au0.6","depends_on_id":"bd-au0","type":"parent-child","created_at":"2025-11-21T21:07:19.432983-05:00","created_by":"daemon"}]}
{"id":"bd-au0.7","title":"Audit and standardize JSON output across all commands","description":"Ensure consistent JSON format and error handling when --json flag is used.\n\n**Scope:**\n1. Verify all commands respect --json flag\n2. Standardize success response format\n3. Standardize error response format\n4. Document JSON schemas\n\n**Commands to audit:**\n- Core CRUD: create, update, delete, show, list, search ‚úì\n- Queries: ready, blocked, stale, count, stats, status\n- Deps: dep add/remove/tree/cycles\n- Labels: label commands\n- Comments: comments add/list/delete\n- Epics: epic status/close-eligible\n- Export/import: already support --json ‚úì\n\n**Testing:**\n- Success cases return valid JSON\n- Error cases return valid JSON (not plain text)\n- Consistent field naming (snake_case vs camelCase)\n- Array vs object wrapping consistency","status":"open","priority":1,"issue_type":"task","created_at":"2025-11-21T21:07:35.304424-05:00","updated_at":"2025-11-21T21:07:35.304424-05:00","dependencies":[{"issue_id":"bd-au0.7","depends_on_id":"bd-au0","type":"parent-child","created_at":"2025-11-21T21:07:35.305663-05:00","created_by":"daemon"}]}
{"id":"bd-au0.8","title":"Improve clean vs cleanup command naming/documentation","description":"Clarify the difference between bd clean and bd cleanup to reduce user confusion.\n\n**Current state:**\n- bd clean: Remove temporary artifacts (.beads/bd.sock, logs, etc.)\n- bd cleanup: Delete old closed issues from database\n\n**Options:**\n1. Rename for clarity:\n   - bd clean ‚Üí bd clean-temp\n   - bd cleanup ‚Üí bd cleanup-issues\n   \n2. Keep names but improve help text and documentation\n\n3. Add prominent warnings in help output\n\n**Preferred approach:** Option 2 (improve documentation)\n- Update short/long descriptions in commands\n- Add examples to help text\n- Update README.md\n- Add cross-references in help output\n\n**Files to modify:**\n- cmd/bd/clean.go\n- cmd/bd/cleanup.go\n- README.md or ADVANCED.md","status":"open","priority":2,"issue_type":"task","created_at":"2025-11-21T21:07:49.960534-05:00","updated_at":"2025-11-21T21:07:49.960534-05:00","dependencies":[{"issue_id":"bd-au0.8","depends_on_id":"bd-au0","type":"parent-child","created_at":"2025-11-21T21:07:49.962743-05:00","created_by":"daemon"}]}
{"id":"bd-au0.9","title":"Review and document rarely-used commands","description":"Document use cases or consider deprecation for infrequently-used commands.\n\n**Commands to review:**\n1. bd rename-prefix - How often is this used? Document use cases\n2. bd detect-pollution - Consider integrating into bd validate\n3. bd migrate-hash-ids - One-time migration, keep but document as legacy\n\n**For each command:**\n- Document typical use cases\n- Add examples to help text\n- Consider if it should be a subcommand instead\n- Add deprecation warning if appropriate\n\n**Not changing:**\n- duplicates ‚úì (useful for data quality)\n- repair-deps ‚úì (useful for fixing broken refs)\n- restore ‚úì (critical for compacted issues)\n- compact ‚úì (performance feature)\n\n**Deliverable:**\n- Updated help text\n- Documentation in ADVANCED.md\n- Deprecation plan if needed","status":"open","priority":3,"issue_type":"task","created_at":"2025-11-21T21:08:05.588275-05:00","updated_at":"2025-11-21T21:08:05.588275-05:00","dependencies":[{"issue_id":"bd-au0.9","depends_on_id":"bd-au0","type":"parent-child","created_at":"2025-11-21T21:08:05.59003-05:00","created_by":"daemon"}]}
{"id":"bd-aydr","title":"Add bd reset command for clean slate restart","description":"Implement a `bd reset` command to reset beads to a clean starting state.\n\n## Context\nGitHub issue #479 - users sometimes get beads into an invalid state after updates, and there's no clean way to start fresh. The git backup/restore mechanism that protects against accidental deletion also makes it hard to intentionally reset.\n\n## Design\n\n### Command Interface\n```\nbd reset [--hard] [--force] [--backup] [--dry-run] [--no-init]\n```\n\n| Flag | Effect |\n|------|--------|\n| `--hard` | Also remove from git index and commit |\n| `--force` | Skip confirmation prompt |\n| `--backup` | Create `.beads-backup-{timestamp}/` first |\n| `--dry-run` | Preview what would happen |\n| `--no-init` | Don't re-initialize after clearing |\n\n### Reset Levels\n1. **Soft Reset (default)** - Kill daemons, clear .beads/, re-init. Git history unchanged.\n2. **Hard Reset (`--hard`)** - Also git rm and commit the removal, then commit fresh state.\n\n### Implementation Flow\n1. Validate .beads/ exists\n2. If not --force: show impact summary, prompt confirmation\n3. If --backup: copy .beads/ to .beads-backup-{timestamp}/\n4. Kill daemons\n5. If --hard: git rm + commit\n6. rm -rf .beads/*\n7. If not --no-init: bd init (and git add+commit if --hard)\n8. Print summary\n\n### Safety Mechanisms\n- Confirmation prompt (skip with --force)\n- Impact summary (issue/tombstone counts)\n- Backup option\n- Dry-run preview\n- Git dirty check warning\n\n### Code Structure\n- `cmd/bd/reset.go` - CLI command\n- `internal/reset/` - Core logic package","status":"closed","priority":2,"issue_type":"epic","created_at":"2025-12-13T08:44:01.38379+11:00","updated_at":"2025-12-14T11:59:26.763667-08:00","closed_at":"2025-12-13T10:18:19.965287+11:00"}
{"id":"bd-aydr.1","title":"Implement core reset package (internal/reset)","description":"Create the core reset logic in internal/reset/ package.\n\n## Responsibilities\n- ResetOptions struct with all flag options\n- CountImpact() - count issues/tombstones that will be deleted\n- ValidateState() - check .beads/ exists, check git dirty state\n- ExecuteReset() - main reset logic (without CLI concerns)\n- Integrate with daemon killall\n\n## Interface Design\n```go\ntype ResetOptions struct {\n    Hard      bool   // Include git operations (git rm, commit)\n    Backup    bool   // Create backup before reset\n    DryRun    bool   // Preview only, don't execute\n    SkipInit  bool   // Don't re-initialize after reset\n}\n\ntype ResetResult struct {\n    IssuesDeleted     int\n    TombstonesDeleted int\n    BackupPath        string  // if backup was created\n    DaemonsKilled     int\n}\n\ntype ImpactSummary struct {\n    IssueCount      int\n    OpenCount       int\n    ClosedCount     int\n    TombstoneCount  int\n    HasUncommitted  bool  // git dirty state\n}\n\nfunc Reset(opts ResetOptions) (*ResetResult, error)\nfunc CountImpact() (*ImpactSummary, error)\nfunc ValidateState() error\n```\n\n## IMPORTANT: CLI vs Core Separation\n- `Force` (skip confirmation) is NOT in ResetOptions - that's a CLI concern\n- Core always executes when called; CLI decides whether to prompt first\n- Keep CLI-agnostic: no prompts, no colored output, no user interaction\n- Return errors for CLI to handle with user-friendly messages\n- Unit testable in isolation\n\n## Dependencies\n- Uses daemon.KillAllDaemons() from internal/daemon/\n- Calls bd init logic after reset (unless SkipInit)","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-13T08:44:50.145364+11:00","updated_at":"2025-12-13T09:20:06.184893+11:00","closed_at":"2025-12-13T09:20:06.184893+11:00","dependencies":[{"issue_id":"bd-aydr.1","depends_on_id":"bd-aydr","type":"parent-child","created_at":"2025-12-13T08:44:50.145775+11:00","created_by":"daemon"}]}
{"id":"bd-aydr.2","title":"Implement backup functionality for reset","description":"Add backup capability that can be used by reset command.\n\n## Functionality\n- Copy .beads/ to .beads-backup-{timestamp}/\n- Timestamp format: YYYYMMDD-HHMMSS\n- Preserve file permissions\n- Return backup path for user feedback\n\n## Location\n`internal/reset/backup.go` - keep with reset package for now (YAGNI)\n\n## Interface\n```go\nfunc CreateBackup(beadsDir string) (backupPath string, err error)\n```\n\n## Notes\n- Simple recursive file copy, no compression needed\n- Error if backup dir already exists (unlikely with timestamp)\n- Backup directories SHOULD be gitignored\n- Add `.beads-backup-*/` pattern to .beads/.gitignore template in doctor package\n- Consider: ListBackups() for future `bd backup list` command (not for this PR)","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-13T08:44:51.306103+11:00","updated_at":"2025-12-13T09:20:20.590488+11:00","closed_at":"2025-12-13T09:20:20.590488+11:00","dependencies":[{"issue_id":"bd-aydr.2","depends_on_id":"bd-aydr","type":"parent-child","created_at":"2025-12-13T08:44:51.306474+11:00","created_by":"daemon"}]}
{"id":"bd-aydr.3","title":"Add git operations for --hard reset","description":"Implement git integration for hard reset mode.\n\n## Operations Needed\n1. `git rm -rf .beads/*.jsonl` - remove data files from index\n2. `git commit -m 'beads: reset to clean state'` - commit removal\n3. After re-init: `git add .beads/` and commit fresh state\n\n## Edge Cases to Handle\n- Uncommitted changes in .beads/ - warn or error\n- Detached HEAD state - warn, maybe block\n- Git not initialized - skip git ops, warn\n- Git operations fail mid-way - clear error messaging\n\n## Interface\n```go\ntype GitState struct {\n    IsRepo       bool\n    IsDirty      bool   // uncommitted changes in .beads/\n    IsDetached   bool   // detached HEAD\n    Branch       string // current branch name\n}\n\nfunc CheckGitState(beadsDir string) (*GitState, error)\nfunc GitRemoveBeads(beadsDir string) error\nfunc GitCommitReset(message string) error\nfunc GitAddAndCommit(beadsDir, message string) error\n```\n\n## Location\n`internal/reset/git.go` - keep with reset package for now\n\nNote: Codebase has no central git package. internal/compact/git.go is compact-specific.\nFuture refactoring could extract shared git utilities, but YAGNI for now.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-13T08:44:52.798312+11:00","updated_at":"2025-12-13T09:17:40.785927+11:00","closed_at":"2025-12-13T09:17:40.785927+11:00","dependencies":[{"issue_id":"bd-aydr.3","depends_on_id":"bd-aydr","type":"parent-child","created_at":"2025-12-13T08:44:52.798715+11:00","created_by":"daemon"}]}
{"id":"bd-aydr.4","title":"Implement CLI command (cmd/bd/reset.go)","description":"Wire up the reset command with Cobra CLI.\n\n## Responsibilities\n- Define command and all flags\n- User confirmation prompt (unless --force)\n- Display impact summary before confirmation\n- Colored output and progress indicators\n- Call core reset package\n- Handle errors with user-friendly messages\n- Register command with rootCmd in init()\n\n## Flags\n```go\n--hard       bool   \"Also remove from git and commit\"\n--force      bool   \"Skip confirmation prompt\"\n--backup     bool   \"Create backup before reset\"\n--dry-run    bool   \"Preview what would happen\"\n--skip-init  bool   \"Do not re-initialize after reset\"\n--verbose    bool   \"Show detailed progress output\"\n```\n\n## Output Format\n```\n‚ö†Ô∏è  This will reset beads to a clean state.\n\nWill be deleted:\n  ‚Ä¢ 47 issues (23 open, 24 closed)\n  ‚Ä¢ 12 tombstones\n\nContinue? [y/N] y\n\n‚Üí Stopping daemons... ‚úì\n‚Üí Removing .beads/... ‚úì\n‚Üí Initializing fresh... ‚úì\n\n‚úì Reset complete. Run 'bd onboard' to set up hooks.\n```\n\n## Implementation Notes\n- Confirmation logic lives HERE, not in core package\n- Use color package (github.com/fatih/color) for output\n- Follow patterns from other commands (init.go, doctor.go)\n- Add to rootCmd in init() function\n\n## File Location\n`cmd/bd/reset.go`","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-13T08:44:54.318854+11:00","updated_at":"2025-12-13T09:59:41.72638+11:00","closed_at":"2025-12-13T09:59:41.72638+11:00","dependencies":[{"issue_id":"bd-aydr.4","depends_on_id":"bd-aydr","type":"parent-child","created_at":"2025-12-13T08:44:54.319237+11:00","created_by":"daemon"},{"issue_id":"bd-aydr.4","depends_on_id":"bd-aydr.1","type":"blocks","created_at":"2025-12-13T08:45:09.762138+11:00","created_by":"daemon"},{"issue_id":"bd-aydr.4","depends_on_id":"bd-aydr.2","type":"blocks","created_at":"2025-12-13T08:45:09.817854+11:00","created_by":"daemon"},{"issue_id":"bd-aydr.4","depends_on_id":"bd-aydr.3","type":"blocks","created_at":"2025-12-13T08:45:09.883658+11:00","created_by":"daemon"}]}
{"id":"bd-aydr.5","title":"Enhance bd doctor to suggest reset for broken states","description":"Update bd doctor to detect severely broken states and suggest reset.\n\n## Detection Criteria\nSuggest reset when:\n- Multiple unfixable errors detected\n- Corrupted JSONL that can't be repaired\n- Schema version mismatch that can't be migrated\n- Daemon state inconsistent and unkillable\n\n## Implementation\nAdd to doctor's check/fix flow:\n```go\nif unfixableErrors \u003e threshold {\n    suggest('State may be too broken to fix. Consider: bd reset')\n}\n```\n\n## Output Example\n```\n‚úó Found 5 unfixable errors\n  \n  Your beads state may be too corrupted to repair.\n  Consider running 'bd reset' to start fresh.\n  (Use 'bd reset --backup' to save current state first)\n```\n\n## Notes\n- Don't auto-run reset, just suggest\n- This is lower priority, can be done in parallel with main work","status":"closed","priority":3,"issue_type":"task","created_at":"2025-12-13T08:44:55.591986+11:00","updated_at":"2025-12-13T10:17:23.4522+11:00","closed_at":"2025-12-13T10:17:23.4522+11:00","dependencies":[{"issue_id":"bd-aydr.5","depends_on_id":"bd-aydr","type":"parent-child","created_at":"2025-12-13T08:44:55.59239+11:00","created_by":"daemon"}]}
{"id":"bd-aydr.6","title":"Add unit tests for reset package","description":"Comprehensive unit tests for internal/reset package.\n\n## Test Cases\n\n### ValidateState tests\n- .beads/ exists ‚Üí success\n- .beads/ missing ‚Üí appropriate error\n- git dirty state detection\n\n### CountImpact tests  \n- Empty .beads/ ‚Üí zero counts\n- With issues ‚Üí correct count (open vs closed)\n- With tombstones ‚Üí correct count\n- Returns HasUncommitted correctly\n\n### Backup tests\n- Creates backup with correct timestamp format\n- Preserves all files and permissions\n- Returns correct path\n- Handles missing .beads/ gracefully\n- Errors on pre-existing backup dir\n\n### Git operation tests\n- CheckGitState detects dirty, detached, not-a-repo\n- GitRemoveBeads removes correct files\n- GitCommitReset creates commit with message\n- Operations skip gracefully when not in git repo\n\n### Reset tests (with mocks/temp dirs)\n- Soft reset removes files, calls init\n- Hard reset includes git operations\n- Dry run doesn't modify anything\n- SkipInit flag prevents re-initialization\n- Daemon killall is called\n- Backup is created when requested\n\n## Approach\n- Can start with interface definitions (TDD style)\n- Use testify for assertions\n- Create temp directories for isolation\n- Mock git operations where needed\n- Test completion depends on implementation tasks\n\n## File Location\n`internal/reset/reset_test.go`\n`internal/reset/backup_test.go`\n`internal/reset/git_test.go`","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-13T08:44:57.01739+11:00","updated_at":"2025-12-13T09:59:20.820314+11:00","closed_at":"2025-12-13T09:59:20.820314+11:00","dependencies":[{"issue_id":"bd-aydr.6","depends_on_id":"bd-aydr","type":"parent-child","created_at":"2025-12-13T08:44:57.017813+11:00","created_by":"daemon"}]}
{"id":"bd-aydr.7","title":"Add integration tests for bd reset command","description":"End-to-end integration tests for the reset command.\n\n## Test Scenarios\n\n### Basic reset\n1. Init beads, create some issues\n2. Run bd reset --force\n3. Verify .beads/ is fresh, issues gone\n\n### Hard reset\n1. Init beads, create issues, commit\n2. Run bd reset --hard --force  \n3. Verify git history has reset commits\n\n### Backup functionality\n1. Init beads, create issues\n2. Run bd reset --backup --force\n3. Verify backup exists with correct contents\n4. Verify main .beads/ is reset\n\n### Dry run\n1. Init beads, create issues\n2. Run bd reset --dry-run\n3. Verify nothing changed\n\n### Confirmation prompt\n1. Init beads\n2. Run bd reset (no --force)\n3. Verify prompts for confirmation\n4. Test both y and n responses\n\n## Location\ntests/integration/reset_test.go or similar","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-13T08:44:58.479282+11:00","updated_at":"2025-12-13T10:15:59.221637+11:00","closed_at":"2025-12-13T10:15:59.221637+11:00","dependencies":[{"issue_id":"bd-aydr.7","depends_on_id":"bd-aydr","type":"parent-child","created_at":"2025-12-13T08:44:58.479686+11:00","created_by":"daemon"},{"issue_id":"bd-aydr.7","depends_on_id":"bd-aydr.4","type":"blocks","created_at":"2025-12-13T08:45:11.15972+11:00","created_by":"daemon"}]}
{"id":"bd-aydr.8","title":"Respond to GitHub issue #479 with solution","description":"Once bd reset is implemented and released, respond to GitHub issue #479.\n\n## Response should include\n- Announce the new bd reset command\n- Show basic usage examples\n- Link to any documentation\n- Thank the user for the feedback\n\n## Example response\n```\nThanks for raising this! We've added a `bd reset` command to handle this case.\n\nUsage:\n- `bd reset` - Reset to clean state (prompts for confirmation)\n- `bd reset --backup` - Create backup first\n- `bd reset --hard` - Also clean up git history\n\nThis is available in version X.Y.Z.\n```\n\n## Notes\n- Wait until feature is merged and released\n- Consider if issue should be closed or left for user confirmation","status":"closed","priority":3,"issue_type":"task","created_at":"2025-12-13T08:45:00.112351+11:00","updated_at":"2025-12-13T10:18:06.646796+11:00","closed_at":"2025-12-13T10:18:06.646796+11:00","dependencies":[{"issue_id":"bd-aydr.8","depends_on_id":"bd-aydr","type":"parent-child","created_at":"2025-12-13T08:45:00.112732+11:00","created_by":"daemon"},{"issue_id":"bd-aydr.8","depends_on_id":"bd-aydr.7","type":"blocks","created_at":"2025-12-13T08:45:12.640243+11:00","created_by":"daemon"}]}
{"id":"bd-aydr.9","title":"Add .beads-backup-* pattern to gitignore template","description":"Update the gitignore template in doctor package to include backup directories.\n\n## Change\nAdd `.beads-backup-*/` to the GitignoreTemplate in `cmd/bd/doctor/gitignore.go`\n\n## Why\nBackup directories created by `bd reset --backup` should not be committed to git.\nThey are local-only recovery tools.\n\n## File\n`cmd/bd/doctor/gitignore.go` - look for GitignoreTemplate constant","status":"closed","priority":3,"issue_type":"task","created_at":"2025-12-13T08:49:42.453483+11:00","updated_at":"2025-12-13T09:16:44.201889+11:00","closed_at":"2025-12-13T09:16:44.201889+11:00","dependencies":[{"issue_id":"bd-aydr.9","depends_on_id":"bd-aydr","type":"parent-child","created_at":"2025-12-13T08:49:42.453886+11:00","created_by":"daemon"}]}
{"id":"bd-b318","title":"Add integration tests for CompactedResult in MCP server","description":"The CompactedResult model is used for list operations when results exceed COMPACTION_THRESHOLD (20 items), but there are no integration tests verifying the actual MCP server behavior with large result sets.\n\n## What's Missing\n- Integration test that mocks a large result set (\u003e20 issues) and verifies CompactedResult is returned\n- Verification that preview_count matches PREVIEW_COUNT (5)\n- Verification that total_count reflects actual result size\n- Test that compaction threshold is configurable (currently hardcoded COMPACTION_THRESHOLD=20)\n\n## Why This Matters\nThe compaction logic is critical for preventing context overflow with large lists. Without integration tests, we can't verify it works correctly with the actual MCP protocol.\n\n## Suggested Implementation\nCreate test_mcp_compaction.py with:\n1. test_list_with_large_result_set_returns_compacted_result()\n2. test_ready_work_respects_compaction_threshold()\n3. test_compacted_result_structure_is_valid()","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-14T14:24:23.824353-08:00","updated_at":"2025-12-14T14:39:50.151444-08:00","closed_at":"2025-12-14T14:39:50.151444-08:00","dependencies":[{"issue_id":"bd-b318","depends_on_id":"bd-otf4","type":"discovered-from","created_at":"2025-12-14T14:24:23.825923-08:00","created_by":"stevey"}]}
{"id":"bd-bgm","title":"Fix unparam unused parameter in cmd/bd/doctor.go:1879","description":"Linting issue: checkGitHooks - path is unused (unparam) at cmd/bd/doctor.go:1879:20. Error: func checkGitHooks(path string) doctorCheck {","status":"open","priority":0,"issue_type":"bug","created_at":"2025-12-07T15:35:25.270293252-07:00","updated_at":"2025-12-07T15:35:25.270293252-07:00"}
{"id":"bd-bmev","title":"Replace Windows CI full test suite with smoke tests","description":"## Problem\n\nWindows CI tests consistently timeout at 30 minutes despite multiple optimization attempts:\n- Split into parallel jobs (cmd vs internal) - still times out\n- RAM disk for temp/cache - marginal improvement (~50%)\n- RAM disk for workspace - breaks due to t.Chdir() incompatibility with ImDisk\n\nRoot cause: Windows I/O is fundamentally 20x slower than Linux:\n- NTFS slow for small file operations\n- Windows Defender scans every file access\n- Git on Windows is 5-10x slower\n- Process spawning is expensive\n\nLinux tests complete in ~1.5 min with race detector. Windows takes 30+ min without.\n\n## Current State\n\n- Windows jobs have continue-on-error: true (don't block PRs)\n- Tests timeout before completing, providing zero signal\n- RAM disk experiments added complexity without solving the problem\n\n## Solution: Smoke Tests Only\n\nReplace full test suite with minimal smoke tests that verify Windows compatibility in \u003c 2 minutes.\n\n### What to Test\n1. Binary builds - go build succeeds (already separate step)\n2. Binary executes - bd version works\n3. Init works - bd init creates valid database\n4. Basic CRUD - create, list, show, update, close\n5. Path handling - Windows backslash paths work\n\n### Proposed CI Change\n\nReplace test-windows-cmd and test-windows-internal with single smoke test job:\n- Build bd.exe\n- Run: bd version\n- Run: bd init --quiet --prefix smoke\n- Run: bd create --title \"Windows smoke test\" --type task\n- Run: bd list\n- Run: bd show smoke-001\n- Run: bd update smoke-001 --status in_progress\n- Run: bd close smoke-001\n\n### Benefits\n- Completes in \u003c 2 minutes vs 30+ minute timeouts\n- Provides actual pass/fail signal\n- Verifies Windows binary works\n- Removes RAM disk complexity\n- Single job instead of two parallel jobs\n\n### Files to Change\n- .github/workflows/ci.yml - Replace test-windows-cmd and test-windows-internal jobs\n\n### Migration Steps\n1. Remove test-windows-cmd job\n2. Remove test-windows-internal job\n3. Add single test-windows job with smoke tests\n4. Remove continue-on-error (tests should now pass reliably)\n5. Clean up RAM disk remnants from previous attempts\n\n### Context\n- Parent issue: bd-5we (Use RAM disk for Windows CI tests)\n- RAM disk approach proved insufficient\n- This is the pragmatic solution after extensive experimentation","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-13T07:28:32.445588-08:00","updated_at":"2025-12-13T10:53:34.683101-08:00","closed_at":"2025-12-13T10:53:34.683101-08:00"}
{"id":"bd-bscs","title":"GH#518: Document bd setup command","description":"bd setup (e.g. bd setup cursor) is undocumented. Users only find it by grepping source. Need proper docs. See: https://github.com/steveyegge/beads/issues/518","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-14T16:31:35.881408-08:00","updated_at":"2025-12-16T01:25:30.837805-08:00","closed_at":"2025-12-16T01:09:09.420428-08:00"}
{"id":"bd-bvec","title":"Test coverage improvement initiative (47.8% ‚Üí 65%)","description":"Umbrella epic for improving overall test coverage from 47.8% to 65%+.\n\n## Summary\n\n| Package | Current | Target | Issue |\n|---------|---------|--------|-------|\n| internal/compact | 18.2% | 70% | bd-thgk |\n| cmd/bd/doctor/fix | 23.9% | 50% | bd-fx7v |\n| cmd/bd | 26.2% | 50% | bd-llfl |\n| internal/daemon | 27.3% | 60% | bd-n386 |\n| cmd/bd/setup | 28.4% | 50% | bd-sh4c |\n| internal/syncbranch | 33.0% | 70% | bd-io8c |\n| internal/export | 37.1% | 60% | bd-6sm6 |\n| internal/lockfile | 42.0% | 60% | bd-9w3s |\n| internal/rpc | 47.5% | 60% | bd-m8ro |\n| internal/beads | 48.1% | 70% | bd-tvu3 |\n| internal/storage | N/A | basic | bd-a15d |\n\n## Packages with good coverage (no action needed)\n- internal/types: 91.0%\n- internal/utils: 88.9%\n- internal/deletions: 84.3%\n- internal/config: 84.2%\n- internal/autoimport: 83.5%\n- internal/validation: 80.8%\n- internal/merge: 78.9%\n- internal/routing: 74.3%\n- internal/storage/sqlite: 73.1%\n- internal/importer: 70.2%\n\nOverall target: 65%+ (from current 47.8%)","status":"open","priority":2,"issue_type":"epic","created_at":"2025-12-13T20:43:22.901825-08:00","updated_at":"2025-12-13T20:43:22.901825-08:00","dependencies":[{"issue_id":"bd-bvec","depends_on_id":"bd-thgk","type":"blocks","created_at":"2025-12-13T20:43:29.536041-08:00","created_by":"daemon"},{"issue_id":"bd-bvec","depends_on_id":"bd-tvu3","type":"blocks","created_at":"2025-12-13T20:43:29.588057-08:00","created_by":"daemon"},{"issue_id":"bd-bvec","depends_on_id":"bd-n386","type":"blocks","created_at":"2025-12-13T20:43:29.637931-08:00","created_by":"daemon"},{"issue_id":"bd-bvec","depends_on_id":"bd-io8c","type":"blocks","created_at":"2025-12-13T20:43:29.689467-08:00","created_by":"daemon"},{"issue_id":"bd-bvec","depends_on_id":"bd-llfl","type":"blocks","created_at":"2025-12-13T20:43:29.738487-08:00","created_by":"daemon"},{"issue_id":"bd-bvec","depends_on_id":"bd-sh4c","type":"blocks","created_at":"2025-12-13T20:43:29.789217-08:00","created_by":"daemon"},{"issue_id":"bd-bvec","depends_on_id":"bd-fx7v","type":"blocks","created_at":"2025-12-13T20:43:29.839732-08:00","created_by":"daemon"},{"issue_id":"bd-bvec","depends_on_id":"bd-6sm6","type":"blocks","created_at":"2025-12-13T20:43:29.887425-08:00","created_by":"daemon"},{"issue_id":"bd-bvec","depends_on_id":"bd-9w3s","type":"blocks","created_at":"2025-12-13T20:43:29.936762-08:00","created_by":"daemon"},{"issue_id":"bd-bvec","depends_on_id":"bd-m8ro","type":"blocks","created_at":"2025-12-13T20:43:29.98703-08:00","created_by":"daemon"},{"issue_id":"bd-bvec","depends_on_id":"bd-a15d","type":"blocks","created_at":"2025-12-13T20:43:30.049603-08:00","created_by":"daemon"}]}
{"id":"bd-bw6","title":"Fix G104 errors unhandled in internal/storage/sqlite/queries.go:1181","description":"Linting issue: G104: Errors unhandled (gosec) at internal/storage/sqlite/queries.go:1181:4. Error: rows.Close()","status":"open","priority":0,"issue_type":"bug","created_at":"2025-12-07T15:35:09.008444133-07:00","updated_at":"2025-12-07T15:35:09.008444133-07:00"}
{"id":"bd-bwdd","title":"GH#497: bd onboard copilot-instructions.md is beads-specific, not generic","description":"bd onboard outputs beads repo specific content (Go/SQLite/Cobra) for copilot-instructions.md instead of a generic template. AGENTS.md output is correct. See: https://github.com/steveyegge/beads/issues/497","status":"in_progress","priority":2,"issue_type":"bug","created_at":"2025-12-14T16:32:18.599655-08:00","updated_at":"2025-12-14T16:52:49.794787-08:00"}
{"id":"bd-bwk2","title":"Centralize error handling patterns in storage layer","description":"80+ instances of inconsistent error handling across sqlite.go with mix of %w, %v, and no wrapping.\n\nLocation: internal/storage/sqlite/sqlite.go (throughout)\n\nProblem:\n- Some use fmt.Errorf(\"op failed: %w\", err) - correct wrapping\n- Some use fmt.Errorf(\"op failed: %v\", err) - loses error chain\n- Some return err directly - no context\n- Hard to debug production issues\n- Can't distinguish error types\n\nSolution: Create internal/storage/sqlite/errors.go:\n- Define sentinel errors (ErrNotFound, ErrInvalidID, etc.)\n- Create wrapDBError(op string, err error) helper\n- Convert sql.ErrNoRows to ErrNotFound\n- Always wrap with operation context\n\nImpact: Lost error context; inconsistent messages; hard to debug\n\nEffort: 5-7 hours","status":"open","priority":1,"issue_type":"task","created_at":"2025-11-16T14:51:54.974909-08:00","updated_at":"2025-11-16T14:51:54.974909-08:00"}
{"id":"bd-bxha","title":"Default to YES for git hooks and merge driver installation","description":"Currently bd init prompts user to install git hooks and merge driver, but setup is incomplete if user declines. Change to install by default unless --skip-hooks or --skip-merge-driver flags are passed. Better safe defaults. If installation fails, warn user and suggest bd doctor --fix.","status":"open","priority":1,"issue_type":"feature","created_at":"2025-11-21T23:16:10.172238-08:00","updated_at":"2025-11-21T23:16:28.369137-08:00","dependencies":[{"issue_id":"bd-bxha","depends_on_id":"bd-tbz3","type":"parent-child","created_at":"2025-11-21T23:16:10.173034-08:00","created_by":"daemon"}]}
{"id":"bd-c3u","title":"Review PR #512: clarify bd ready docs","description":"Review and merge PR #512 from aspiers. This PR clarifies what bd ready does after git pull in README.md. Simple 1-line change. URL: https://github.com/anthropics/beads/pull/512","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-13T08:15:13.405161+11:00","updated_at":"2025-12-13T07:07:29.641265-08:00","closed_at":"2025-12-13T07:07:29.641265-08:00"}
{"id":"bd-c83r","title":"Prevent multiple daemons from running on the same repo","description":"Multiple bd daemons running on the same repo clone causes race conditions and data corruption risks.\n\n**Problem:**\n- Nothing prevents spawning multiple daemons for the same repository\n- Multiple daemons watching the same files can conflict during sync operations\n- Observed: 4 daemons running simultaneously caused sync race condition\n\n**Solution:**\nImplement daemon singleton enforcement per repo:\n1. Use a lock file (e.g., .beads/.daemon.lock) with PID\n2. On daemon start, check if lock exists and process is alive\n3. If stale lock (dead PID), clean up and acquire lock\n4. If active daemon exists, either:\n   - Exit with message 'daemon already running (PID xxx)'\n   - Or offer --replace flag to kill existing and take over\n5. Release lock on graceful shutdown\n\n**Edge cases to handle:**\n- Daemon crashes without releasing lock (stale PID detection)\n- Multiple repos in same directory tree (each repo gets own lock)\n- Race between two daemons starting simultaneously (atomic lock acquisition)","status":"closed","priority":2,"issue_type":"bug","created_at":"2025-12-13T06:37:23.377131-08:00","updated_at":"2025-12-16T01:25:30.840547-08:00","closed_at":"2025-12-14T17:34:14.990077-08:00"}
{"id":"bd-cb2f","title":"Week 1 task","description":"","status":"closed","priority":2,"issue_type":"task","created_at":"2025-11-03T19:11:59.358093-08:00","updated_at":"2025-12-13T23:29:56.877967-08:00","closed_at":"2025-12-13T23:29:56.877967-08:00"}
{"id":"bd-cddj","title":"GH#520: Daemon sync-branch commit fails with pre-commit hooks (needs --no-verify)","description":"gitCommitInWorktree in daemon_sync_branch.go missing --no-verify flag, causing commit failures when pre-commit hooks installed. Library function in worktree.go:684 has correct impl. See: https://github.com/steveyegge/beads/issues/520","status":"in_progress","priority":1,"issue_type":"bug","created_at":"2025-12-14T16:31:33.151247-08:00","updated_at":"2025-12-14T16:52:49.801315-08:00"}
{"id":"bd-crgr","title":"GH#517: Claude sets priority wrong on new install","description":"Claude uses 'medium/high/low' for priority instead of P0-P4. Update bd prime/onboard output to be clearer about priority syntax. See GitHub issue #517.","status":"closed","priority":2,"issue_type":"bug","created_at":"2025-12-16T01:03:34.803084-08:00","updated_at":"2025-12-16T01:25:30.838756-08:00","closed_at":"2025-12-16T01:08:56.214718-08:00"}
{"id":"bd-d148","title":"GH#483: Pre-commit hook fails unnecessarily when .beads removed","description":"Pre-commit hook fails on bd sync when .beads directory exists but user is on branch without beads. Should exit gracefully. See GitHub issue #483.","status":"open","priority":2,"issue_type":"bug","created_at":"2025-12-16T01:03:40.049785-08:00","updated_at":"2025-12-16T01:03:40.049785-08:00"}
{"id":"bd-d3e5","title":"Test issue 2","description":"","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-16T01:09:02.476072-08:00","updated_at":"2025-12-16T01:09:02.476072-08:00","closed_at":"2025-12-14T00:32:13.890274-08:00"}
{"id":"bd-de6","title":"Fix FindBeadsDir to prioritize main repo .beads for worktrees","description":"The FindBeadsDir function should prioritize finding .beads in the main repository root when accessed from a worktree, rather than finding worktree-local .beads directories. This ensures proper sharing of the database across all worktrees.","status":"open","priority":2,"issue_type":"bug","created_at":"2025-12-07T16:48:36.883117467-07:00","updated_at":"2025-12-07T16:48:36.883117467-07:00"}
{"id":"bd-dh8a","title":"Optimize --sandbox mode: skip FlushManager","description":"When `--sandbox` mode is enabled, skip FlushManager creation entirely.\n\n## Current Behavior\n`main.go:561` always creates FlushManager:\n```go\nflushManager = NewFlushManager(autoFlushEnabled, getDebounceDuration())\n```\n\nEven with `--sandbox` (which sets `noAutoFlush=true`), the FlushManager goroutine is still running.\n\n## Proposed Change\n```go\n// Only create FlushManager if we might actually need it\nif !sandboxMode \u0026\u0026 autoFlushEnabled {\n    flushManager = NewFlushManager(true, getDebounceDuration())\n}\n```\n\n## Handle nil FlushManager\nUpdate PersistentPostRun to handle nil:\n```go\nif flushManager != nil \u0026\u0026 !skipFinalFlush {\n    if err := flushManager.Shutdown(); err != nil {\n        // ...\n    }\n}\n```\n\n## Synchronous Export Fallback\nWhen sandbox mode + write operation occurs, do synchronous export:\n```go\nif sandboxMode \u0026\u0026 isDirty {\n    performSynchronousExport()\n}\n```\n\n## Also: Default lock-timeout to 100ms in sandbox mode\nIn PersistentPreRun, when sandboxMode is detected:\n```go\nif sandboxMode {\n    noDaemon = true\n    noAutoFlush = true\n    noAutoImport = true\n    if lockTimeout == 30*time.Second { // Not explicitly set\n        lockTimeout = 100 * time.Millisecond\n    }\n}\n```\n\nPart of bd-olc1","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-13T17:54:58.594335-08:00","updated_at":"2025-12-13T18:06:10.370218-08:00","closed_at":"2025-12-13T18:06:10.370218-08:00","dependencies":[{"issue_id":"bd-dh8a","depends_on_id":"bd-59er","type":"blocks","created_at":"2025-12-13T17:55:26.590151-08:00","created_by":"daemon"},{"issue_id":"bd-dh8a","depends_on_id":"bd-r4od","type":"blocks","created_at":"2025-12-13T17:55:26.626988-08:00","created_by":"daemon"}]}
{"id":"bd-dow9","title":"Improve CheckStaleness error handling","description":"## Problem\n\nCheckStaleness returns 'false' (not stale) for multiple error conditions instead of returning errors. This masks problems.\n\n**Location:** internal/autoimport/autoimport.go:253-285\n\n## Edge Cases That Return False\n\n1. **Invalid last_import_time format** (line 259-262)\n   - Corrupted metadata returns 'not stale'\n   - Could show stale data\n\n2. **No JSONL file found** (line 267-277)\n   - If glob fails, falls back to 'issues.jsonl'\n   - If that's empty, returns 'not stale'\n\n3. **JSONL stat fails** (line 279-282)\n   - Permission denied, file missing\n   - Returns 'not stale' even though can't verify\n\n## Current Code\n\n```go\nlastImportTime, err := time.Parse(time.RFC3339, lastImportStr)\nif err \\!= nil {\n    return false, nil  // ‚Üê Should return error\n}\n\n// ...\n\nif jsonlPath == \"\" {\n    return false, nil  // ‚Üê Should return error\n}\n\nstat, err := os.Stat(jsonlPath)\nif err \\!= nil {\n    return false, nil  // ‚Üê Should return error\n}\n```\n\n## Fix\n\n```go\nlastImportTime, err := time.Parse(time.RFC3339, lastImportStr)\nif err \\!= nil {\n    return false, fmt.Errorf(\"corrupted last_import_time: %w\", err)\n}\n\n// ...\n\nif jsonlPath == \"\" {\n    return false, fmt.Errorf(\"no JSONL file found\")\n}\n\nstat, err := os.Stat(jsonlPath)\nif err \\!= nil {\n    return false, fmt.Errorf(\"cannot stat JSONL: %w\", err)\n}\n```\n\n## Impact\nMedium - edge cases are rare but should be handled\n\n## Effort  \n30 minutes - requires updating callers in RPC server\n\n## Dependencies\nRequires: bd-n4td (warning on errors)","status":"closed","priority":2,"issue_type":"bug","created_at":"2025-11-20T20:16:45.658965-05:00","updated_at":"2025-12-13T23:32:56.573608-08:00","closed_at":"2025-12-13T23:32:56.573608-08:00"}
{"id":"bd-dvw8","title":"GH#523: Fix closed issues missing closed_at timestamp during db upgrade","description":"Old beads databases may have closed issues without closed_at timestamps, causing 'closed issues must have closed_at timestamp' validation errors on upgrade to 0.29.0. Need defensive handling during import. See: https://github.com/steveyegge/beads/issues/523","status":"closed","priority":1,"issue_type":"bug","created_at":"2025-12-14T16:31:30.421555-08:00","updated_at":"2025-12-16T01:25:30.840833-08:00","closed_at":"2025-12-14T17:29:34.746247-08:00"}
{"id":"bd-dyy","title":"Review PR #513: fix hooks install docs","description":"Review and merge PR #513 from aspiers. This PR fixes incorrect docs for how to install git hooks - updates README to use bd hooks install instead of removed install.sh. Simple 1-line change. URL: https://github.com/anthropics/beads/pull/513","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-13T08:15:14.838772+11:00","updated_at":"2025-12-13T07:07:19.718544-08:00","closed_at":"2025-12-13T07:07:19.718544-08:00"}
{"id":"bd-e0o7","title":"Refactor: extract common helpers in sync-branch hook checks","description":"Code review of #532 fix identified duplication between checkSyncBranchHookCompatibility and checkSyncBranchHookQuick.\n\nSuggested refactoring:\n1. Extract getPrePushHookPath(path string) helper for git dir + hook path resolution\n2. Extract extractHookVersion(hookContent string) helper for version parsing\n3. Consider whether Warning for custom hooks is appropriate (vs OK with info message)\n4. Document the intentional behavior difference between full check (Warning for custom) and quick check (OK for custom)","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-13T18:04:04.220868-08:00","updated_at":"2025-12-16T01:25:30.839387-08:00","closed_at":"2025-12-14T17:36:22.147803-08:00"}
{"id":"bd-e1085716","title":"bd validate - Comprehensive health check","description":"Run all validation checks in one command.\n\nChecks:\n- Duplicates\n- Orphaned dependencies\n- Test pollution\n- Git conflicts\n\nSupports --fix-all for auto-repair.\n\nDepends on bd-cbed9619.1, bd-0dcea000, bd-31aab707, bd-9826b69a.\n\nFiles: cmd/bd/validate.go (new)","status":"open","priority":1,"issue_type":"task","created_at":"2025-10-29T23:05:13.980679-07:00","updated_at":"2025-10-30T17:12:58.19736-07:00"}
{"id":"bd-ee1","title":"Add security tests for WriteFile permissions in doctor command","description":"Test coverage gap identified by automated analysis (vc-217).\n\n**Original Issue:** [deleted:[deleted:bd-da96-baseline-lint]]\n\nIn cmd/bd/doctor/gitignore.go:98, os.WriteFile uses 0644 permissions, flagged by gosec G306 as potentially too permissive.\n\nAdd tests to verify:\n- File is created with appropriate permissions (0600 or less)\n- Existing file permissions are not loosened\n- File ownership is correct\n- Sensitive data handling if .gitignore contains secrets\n\nThis ensures .gitignore files are created with secure permissions to prevent unauthorized access.\n\n_This issue was automatically created by AI test coverage analysis._","status":"open","priority":1,"issue_type":"task","created_at":"2025-11-21T10:25:33.529153-05:00","updated_at":"2025-11-22T14:57:44.539058246-05:00"}
{"id":"bd-eeqf","title":"GH#486: Claude forgets beads workflow mid-session","description":"Claude progressively reverts to TodoWrite or skips tracking despite CLAUDE.md instructions. Happens after context resets or long sessions. Need stronger prompting or hooks. See: https://github.com/steveyegge/beads/issues/486","status":"in_progress","priority":2,"issue_type":"bug","created_at":"2025-12-14T16:32:21.544338-08:00","updated_at":"2025-12-14T16:52:49.797933-08:00"}
{"id":"bd-efm","title":"sync tries to create worktree in .git file","description":"example: bd sync --no-daemon\n‚Üí Exporting pending changes to JSONL...\n‚Üí Committing changes to sync branch 'worktree-db-fail'...\nError committing to sync branch: failed to create worktree: failed to create worktree parent directory: mkdir /var/home/matt/dev/beads/worktree-db-fail/.git: not a directory","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-07T15:43:38.086614222-07:00","updated_at":"2025-12-13T23:32:36.995519-08:00","closed_at":"2025-12-13T23:32:36.995519-08:00"}
{"id":"bd-er7r","title":"GH#509: bd fails to find .beads from nested worktrees","description":"findDatabaseInTree stops at worktree git root, missing .beads in parent repo. Should check git-common-dir and search past worktree root. See: https://github.com/steveyegge/beads/issues/509","status":"in_progress","priority":2,"issue_type":"bug","created_at":"2025-12-14T16:32:00.082813-08:00","updated_at":"2025-12-14T16:52:49.8029-08:00"}
{"id":"bd-eyto","title":"Time-dependent tests may be flaky near TTL boundary","description":"Several tombstone merge tests use time.Now() to create test data: time.Now().Add(-24 * time.Hour), time.Now().Add(-60 * 24 * time.Hour), etc. While these work reliably in practice (24h vs 30d TTL has large margin), they could theoretically be flaky if: 1) Tests run slowly, 2) System clock changes during test, 3) TTL constants change. Recommendation: Consider using a fixed reference time or time injection for deterministic tests. Lower priority since current margin is large. Files: internal/merge/merge_test.go:1337-1338, 1352-1353, 1548-1549, 1590-1591","status":"open","priority":3,"issue_type":"task","created_at":"2025-12-05T16:37:02.348143-08:00","updated_at":"2025-12-05T16:37:02.348143-08:00"}
{"id":"bd-ffr9","title":"deletions.jsonl recreated locally after tombstone migration","description":"After running bd migrate-tombstones and removing deletions.jsonl from git, the file gets recreated locally on subsequent bd commands.\n\n**Steps to reproduce:**\n1. Run bd migrate-tombstones (converts to inline tombstones)\n2. Remove deletions.jsonl from git and filesystem\n3. Run bd sync or bd stats\n4. deletions.jsonl reappears\n\n**Expected behavior:**\nAfter migration, deletions.jsonl should not be recreated. All tombstone data should come from inline tombstones in issues.jsonl.\n\n**Workaround:** Add deletions.jsonl to .gitignore to prevent re-tracking. File still gets created but won't pollute the repo.","status":"closed","priority":2,"issue_type":"bug","created_at":"2025-12-15T17:28:50.949625-08:00","updated_at":"2025-12-16T00:54:56.459227-08:00","closed_at":"2025-12-16T00:54:56.459227-08:00"}
{"id":"bd-fi05","title":"bd sync fails with orphaned issues and duplicate ID conflict","description":"After fixing the deleted_at TEXT column scanning bug (commit 18b1eb2), bd sync still fails with two issues:\n\n1. Orphan Detection Warning: 12 orphaned child issues whose parents no longer exist (bd-cb64c226.* and bd-cbed9619.*)\n\n2. Import Failure: UNIQUE constraint failed for bd-360 - this tombstone exists in both DB and JSONL\n\nError: \"Import failed: error creating depth-0 issues: bulk insert issues: failed to insert issue bd-360: sqlite3: constraint failed: UNIQUE constraint failed: issues.id\"\n\nFix options:\n- Delete orphaned child issues with bd delete\n- Resolve bd-360 duplicate (in deletions.jsonl vs tombstone in DB)\n- Reset sync branch: git branch -f beads-sync main \u0026\u0026 git push --force-with-lease origin beads-sync","notes":"Fixed tombstone constraint violation bug. When deleting closed issues, the CHECK constraint (status = 'closed') = (closed_at IS NOT NULL) was violated because CreateTombstone didn't clear closed_at. Fix: set closed_at = NULL in tombstone creation SQL.\n\nThe sync data corruption (orphaned issues in beads-sync branch) requires manual cleanup: reset sync branch with 'git branch -f beads-sync main \u0026\u0026 git push --force-with-lease origin beads-sync'","status":"closed","priority":2,"issue_type":"bug","created_at":"2025-12-13T07:14:33.831346-08:00","updated_at":"2025-12-13T10:50:48.545465-08:00","closed_at":"2025-12-13T07:30:33.843986-08:00"}
{"id":"bd-fx7v","title":"Improve test coverage for cmd/bd/doctor/fix (23.9% ‚Üí 50%)","description":"The doctor/fix package has only 23.9% test coverage. The doctor fix functionality is important for troubleshooting.\n\nCurrent coverage: 23.9%\nTarget coverage: 50%","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-13T20:43:05.67127-08:00","updated_at":"2025-12-13T21:01:20.839298-08:00"}
{"id":"bd-g9eu","title":"Investigate TestRoutingIntegration failure","description":"TestRoutingIntegration/maintainer_with_SSH_remote failed during pre-commit check with \"expected role maintainer, got contributor\".\nThis occurred while running `go test -short ./...` on darwin/arm64.\nThe failure appears unrelated to storage/sqlite changes.\nNeed to investigate if this is a flaky test or environmental issue.","status":"open","priority":2,"issue_type":"task","created_at":"2025-11-20T15:55:19.337094-08:00","updated_at":"2025-11-20T15:55:19.337094-08:00"}
{"id":"bd-h5n1","title":"bd cleanup should also prune expired tombstones","description":"## Problem\n\n`bd cleanup` deletes closed issues (converting them to tombstones) but does NOT prune expired tombstones. Users expect 'cleanup' to do comprehensive cleanup.\n\n## Current Behavior\n\n1. `bd cleanup --force` ‚Üí converts closed issues to tombstones\n2. Expired tombstones (\u003e30 days) remain in issues.jsonl\n3. User must separately run `bd compact` to prune tombstones\n4. `bd doctor` warns about expired tombstones: 'Run bd compact to prune'\n\n## Expected Behavior\n\n`bd cleanup` should also prune expired tombstones from issues.jsonl.\n\n## Impact\n\nWith v0.30.0 making tombstones the default migration path, this UX gap becomes more visible. Users cleaning up their database shouldn't need to know about a separate `bd compact` command.\n\n## Proposed Solution\n\nCall `pruneExpiredTombstones()` at the end of the cleanup command (same function used by compact). Report results:\n\n```\n‚úì Deleted 15 closed issue(s)\n‚úì Pruned 3 expired tombstone(s) (older than 30 days)\n```\n\n## Files to Modify\n\n- `cmd/bd/cleanup.go` - Add call to pruneExpiredTombstones after deleteBatch\n- May need to move pruneExpiredTombstones to shared location if not already accessible\n\n## Acceptance Criteria\n\n- [ ] `bd cleanup --force` prunes expired tombstones after deleting closed issues\n- [ ] `bd cleanup --dry-run` shows what tombstones would be pruned\n- [ ] JSON output includes tombstone prune results","status":"closed","priority":1,"issue_type":"bug","created_at":"2025-12-13T23:49:35.963356-08:00","updated_at":"2025-12-16T01:25:30.837479-08:00","closed_at":"2025-12-14T17:29:50.073906-08:00","deleted_at":"2025-12-14T00:25:57.3165-08:00","deleted_by":"git-history-backfill","delete_reason":"recovered from git history (pruned from manifest)","original_type":"bug"}
{"id":"bd-hkr6","title":"GH#518: Document bd setup command","description":"bd setup is undiscoverable. Add to README/docs. Currently only findable by grepping source. See GitHub issue #518.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-16T01:03:54.664668-08:00","updated_at":"2025-12-16T01:25:30.838128-08:00","closed_at":"2025-12-16T01:09:56.734268-08:00"}
{"id":"bd-hlsw","title":"Add sync resilience guardrails for forced pushes and prefix mismatches","description":"Beads can get into unrecoverable sync states when remote forces pushes occur (e.g., rebases) combined with prefix mismatches from multi-worker scenarios. Add detection, prevention, and auto-recovery features to handle this gracefully.","status":"open","priority":2,"issue_type":"epic","created_at":"2025-12-14T10:40:14.872875259-07:00","updated_at":"2025-12-14T10:40:14.872875259-07:00"}
{"id":"bd-hlsw.1","title":"Pre-sync integrity check (bd sync --check)","description":"Add bd sync --check flag that detects problematic states before attempting sync: forced pushes on sync branch (via git reflog), prefix mismatches in JSONL, orphaned children with missing parents. Output combined diagnostic without modifying state.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-14T10:40:20.493608412-07:00","updated_at":"2025-12-16T01:25:30.838438-08:00","closed_at":"2025-12-16T01:13:33.639724-08:00","dependencies":[{"issue_id":"bd-hlsw.1","depends_on_id":"bd-hlsw","type":"parent-child","created_at":"2025-12-14T10:40:20.494249154-07:00","created_by":"daemon"}]}
{"id":"bd-hlsw.2","title":"Improve sync error messages","description":"When bd sync fails, immediately surface the actual root cause (prefix mismatch, orphaned children, forced push detected, etc.) instead of requiring multiple retries to discover it. Make errors actionable with specific recovery steps.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-14T10:40:20.545731796-07:00","updated_at":"2025-12-16T01:25:30.839958-08:00","closed_at":"2025-12-16T01:17:06.844571-08:00","dependencies":[{"issue_id":"bd-hlsw.2","depends_on_id":"bd-hlsw","type":"parent-child","created_at":"2025-12-14T10:40:20.546686125-07:00","created_by":"daemon"}]}
{"id":"bd-hlsw.3","title":"Auto-recovery mode (bd sync --auto-recover)","description":"Add bd sync --auto-recover flag that: detects problematic sync state, backs up .beads/issues.db with timestamp, rebuilds DB from JSONL atomically, verifies consistency, reports what was fixed. Provides safety valve when sync integrity fails.","status":"open","priority":3,"issue_type":"task","created_at":"2025-12-14T10:40:20.599836875-07:00","updated_at":"2025-12-14T10:40:20.599836875-07:00","dependencies":[{"issue_id":"bd-hlsw.3","depends_on_id":"bd-hlsw","type":"parent-child","created_at":"2025-12-14T10:40:20.600435888-07:00","created_by":"daemon"}]}
{"id":"bd-hlsw.4","title":"Sync branch integrity guards","description":"Track sync branch parent commit. If sync branch was force-pushed, warn user and require confirmation before proceeding. Add option to reset to remote if user accepts rebase. Prevents silent corruption from forced pushes.","status":"open","priority":3,"issue_type":"task","created_at":"2025-12-14T10:40:20.645402352-07:00","updated_at":"2025-12-14T10:40:20.645402352-07:00","dependencies":[{"issue_id":"bd-hlsw.4","depends_on_id":"bd-hlsw","type":"parent-child","created_at":"2025-12-14T10:40:20.646425761-07:00","created_by":"daemon"}]}
{"id":"bd-hnkg","title":"GH#540: Add silent quick-capture mode (bd q)","description":"Add bd q alias for quick capture that outputs only issue ID. Useful for piping/scripting. See GitHub issue #540.","status":"open","priority":2,"issue_type":"feature","created_at":"2025-12-16T01:03:38.260135-08:00","updated_at":"2025-12-16T01:03:38.260135-08:00"}
{"id":"bd-hxou","title":"Daemon performAutoImport should update jsonl_content_hash after import","description":"The daemon's performAutoImport function was not updating jsonl_content_hash after successful import, unlike the CLI import path. This could cause repeated imports if the file hash and DB hash diverge.\n\nFix: Added hash update after validatePostImport succeeds, using repoKey for multi-repo support.","status":"closed","priority":2,"issue_type":"bug","created_at":"2025-12-13T06:44:04.442976-08:00","updated_at":"2025-12-13T06:44:09.546976-08:00","closed_at":"2025-12-13T06:44:09.546976-08:00"}
{"id":"bd-hy9p","title":"Add --body-file flag to bd create for reading descriptions from files","description":"## Problem\n\nCreating issues with long/complex descriptions via CLI requires shell escaping gymnastics:\n\n```bash\n# Current workaround - awkward heredoc quoting\nbd create --title=\"...\" --description=\"$(cat \u003c\u003c'EOF'\n...markdown...\nEOF\n)\"\n\n# Often fails with quote escaping errors in eval context\n# Agents resort to writing temp files then reading them\n```\n\n## Proposed Solution\n\nAdd `--body-file` and `--description-file` flags to read description from a file, matching `gh` CLI pattern.\n\n```bash\n# Natural pattern that aligns with training data\ncat \u003e /tmp/desc.md \u003c\u003c 'EOF'\n...markdown content...\nEOF\n\nbd create --title=\"...\" --body-file=/tmp/desc.md\n```\n\n## Implementation\n\n### 1. Add new flags to `bd create`\n\n```go\ncreateCmd.Flags().String(\"body-file\", \"\", \"Read description from file (use - for stdin)\")\ncreateCmd.Flags().String(\"description-file\", \"\", \"Alias for --body-file\")\n```\n\n### 2. Flag precedence\n\n- If `--body-file` or `--description-file` is provided, read from file\n- If value is `-`, read from stdin\n- Otherwise fall back to `--body` or `--description` flag\n- If neither provided, description is empty (current behavior)\n\n### 3. Error handling\n\n- File doesn't exist ‚Üí clear error message\n- File not readable ‚Üí clear error message\n- stdin specified but not available ‚Üí clear error message\n\n## Benefits\n\n‚úÖ **Matches training data**: `gh issue create --body-file file.txt` is a common pattern\n‚úÖ **No shell escaping issues**: File content is read directly\n‚úÖ **Works with any content**: Markdown, special characters, quotes, etc.\n‚úÖ **Agent-friendly**: Agents already write complex content to temp files\n‚úÖ **User-friendly**: Easier for humans too when pasting long descriptions\n\n## Related Commands\n\nConsider adding similar support to:\n- `bd update --body-file` (for updating descriptions)\n- `bd comment --body-file` (if/when we add comments)\n\n## Examples\n\n```bash\n# From file\nbd create --title=\"Add new feature\" --body-file=feature.md\n\n# From stdin\necho \"Quick description\" | bd create --title=\"Bug fix\" --body-file=-\n\n# With other flags\nbd create \\\n  --title=\"Security issue\" \\\n  --type=bug \\\n  --priority=0 \\\n  --body-file=security-report.md \\\n  --label=security\n```\n\n## Testing\n\n- Test with normal files\n- Test with stdin (`-`)\n- Test with non-existent files (error handling)\n- Test with binary files (should handle gracefully)\n- Test with empty files (valid - empty description)\n- Test that `--description-file` and `--body-file` are equivalent aliases","status":"open","priority":1,"issue_type":"feature","created_at":"2025-11-22T00:02:08.762684-08:00","updated_at":"2025-11-22T00:02:08.762684-08:00"}
{"id":"bd-in7q","title":"Fix: bd migrate-tombstones corrupts deletions manifest","description":"When running 'bd migrate-tombstones' followed by 'bd sync', the operation adds thousands of issues to deletions.jsonl with author 'bd-doctor-hydrate' that should never have been deleted. This causes:\n1. Issues are marked as deleted that were never intended for deletion\n2. Subsequent 'bd sync' fails with 3-way merge errors\n3. The migration operation corrupts database state\n\n## Root Cause\nThe tombstone migration logic incorrectly identifies issues that should be migrated as 'deleted issues' and adds them to the deletions manifest instead of converting them to inline tombstones.\n\n## Reproduction\n1. bd sync --import-only\n2. bd migrate-tombstones\n3. bd sync\nResult: See thousands of 'Skipping bd-xxxx (in deletions manifest: deleted 2025-12-14 by bd-doctor-hydrate)' lines and 3-way merge failures\n\n## Impact\n- Database becomes inconsistent\n- Issues permanently lost from local database\n- Requires full reset to recover\n\n## Files to Investigate\n- cmd/bd/migrate_tombstones.go - migration logic\n- deletions manifest handling during migration","status":"closed","priority":0,"issue_type":"bug","created_at":"2025-12-14T11:22:23.464098142-07:00","updated_at":"2025-12-14T11:35:25.916924256-07:00","closed_at":"2025-12-14T11:35:25.916924256-07:00"}
{"id":"bd-io8c","title":"Improve test coverage for internal/syncbranch (33.0% ‚Üí 70%)","description":"The syncbranch package has only 33.0% test coverage. This package handles git sync operations and is critical for data integrity.\n\nCurrent coverage: 33.0%\nTarget coverage: 70%","status":"open","priority":1,"issue_type":"task","created_at":"2025-12-13T20:43:02.079145-08:00","updated_at":"2025-12-13T21:01:14.972533-08:00"}
{"id":"bd-iq7n","title":"Audit and fix JSONL filename mismatches across all repo clones","description":"## Problem\n\nMultiple clones of repos are configured with different JSONL filenames (issues.jsonl vs beads.jsonl), causing:\n1. JSONL files to be resurrected after deletion (one clone pushes issues.jsonl, another pushes beads.jsonl)\n2. Agents unable to see issues filed by other agents after sync\n3. Merge conflicts and data inconsistencies\n\n## Root Cause\n\nWhen repos were \"bd doctored\" or initialized at different times, some got issues.jsonl (old default) and others got beads.jsonl (Beads repo specific). These clones push their respective files, creating duplicates.\n\n## Task\n\nScan all repo clones under ~/src/ (1-2 levels deep) and standardize their JSONL configuration.\n\n### Step 1: Find all beads-enabled repos\n\n```bash\n# Find all directories named 'beads' at levels 1-2 under ~/src/\nfind ~/src -maxdepth 2 -type d -name beads\n```\n\n### Step 2: For each repo found, check configuration\n\nFor each directory from Step 1, check:\n- Does `.beads/metadata.json` exist?\n- What is the `jsonl_export` value?\n- What JSONL files actually exist in `.beads/`?\n- Are there multiple JSONL files (problem!)?\n\n### Step 3: Create audit report\n\nGenerate a report showing:\n```\nRepo Path                           | Config        | Actual Files           | Status\n----------------------------------- | ------------- | ---------------------- | --------\n~/src/beads                         | beads.jsonl   | beads.jsonl            | OK\n~/src/dave/beads                    | issues.jsonl  | issues.jsonl           | MISMATCH\n~/src/emma/beads                    | issues.jsonl  | issues.jsonl, beads.jsonl | DUPLICATE!\n```\n\n### Step 4: Determine canonical name for each repo\n\nFor repos that are the SAME git repository (check `git remote -v`):\n- Group them together\n- Determine which JSONL filename should be canonical (majority wins, or beads.jsonl for the beads repo itself)\n- List which clones need to be updated\n\n### Step 5: Generate fix script\n\nCreate a script that for each mismatched clone:\n1. Updates `.beads/metadata.json` to use the canonical name\n2. If JSONL file needs renaming: `git mv .beads/old.jsonl .beads/new.jsonl`\n3. Removes any duplicate JSONL files: `git rm .beads/duplicate.jsonl`\n4. Commits the change\n5. Syncs: `bd sync`\n\n### Expected Output\n\n1. Audit report showing all repos and their config status\n2. List of repos grouped by git remote (same repository)\n3. Fix script or manual instructions for standardizing each repo\n4. Verification that after fixes, all clones of the same repo use the same JSONL filename\n\n### Edge Cases\n\n- Handle repos without metadata.json (use default discovery)\n- Handle repos with no git remote (standalone/local)\n- Handle repos that are not git repositories\n- Don't modify repos with uncommitted changes (warn instead)\n\n### Success Criteria\n\n- All clones of the same git repository use the same JSONL filename\n- No duplicate JSONL files in any repo\n- All configurations documented in metadata.json\n- bd doctor passes on all repos","status":"open","priority":0,"issue_type":"task","created_at":"2025-11-21T23:58:35.044762-08:00","updated_at":"2025-11-21T23:58:35.044762-08:00"}
{"id":"bd-j3il","title":"Add bd reset command for clean slate restart","description":"Implement a command to reset beads to a clean starting state.\n\n**Context:** GitHub issue #479 - users sometimes get beads into an invalid state after updates, and there's no clean way to start fresh. The git backup/restore mechanism that protects against accidental deletion also makes it hard to intentionally reset.\n\n**Current workaround** (from maphew):\n```bash\nbd daemons killall\ngit rm .beads/*.jsonl\ngit commit -m 'remove old issues'\nrm .beads/*\nbd init\nbd onboard\n```\n\n**Desired:** A proper `bd reset` command that handles this cleanly and safely.","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-12-13T08:41:34.956552+11:00","updated_at":"2025-12-13T08:43:49.970591+11:00","closed_at":"2025-12-13T08:43:49.970591+11:00"}
{"id":"bd-j6lr","title":"GH#402: Add --parent flag documentation to bd onboard","description":"bd onboard output is missing --parent flag for epic subtasks. Agents guess wrong syntax (--deps parent:). See GitHub issue #402.","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-16T01:03:56.594829-08:00","updated_at":"2025-12-16T01:03:56.594829-08:00"}
{"id":"bd-jgxi","title":"Auto-migrate database on CLI version bump","description":"When CLI is upgraded (e.g., 0.24.0 ‚Üí 0.24.1), database version becomes stale. Add auto-migration in PersistentPreRun or daemon startup. Check dbVersion != CLIVersion and run bd migrate automatically. Fixes recurring UX issue where bd doctor shows version mismatch after every CLI upgrade.","status":"open","priority":0,"issue_type":"feature","created_at":"2025-11-21T23:16:09.004619-08:00","updated_at":"2025-11-21T23:16:27.229388-08:00","dependencies":[{"issue_id":"bd-jgxi","depends_on_id":"bd-tbz3","type":"parent-child","created_at":"2025-11-21T23:16:09.005513-08:00","created_by":"daemon"}]}
{"id":"bd-k92d","title":"Critical: Beads deletes issues during sync (GH#464)","description":"# Findings\n\n## Root Cause 1: git-history-backfill deletes issues during repo ID mismatch\n\n**Location:** internal/importer/importer.go, purgeDeletedIssues()\n\nThe git-history-backfill mechanism checks git history to find deleted issues. When there's a repo ID mismatch (e.g., database from a different clone or after remote URL change), this can incorrectly treat local issues as deleted because they don't exist in the remote's git history.\n\n**Fix Applied:** Added safety guard at lines 971-987 in importer.go that:\n- Checks issue status before deletion via git-history-backfill\n- Prevents deletion of open/in_progress issues\n- Provides clear warning with actionable steps\n- Suggests using --no-git-history flag or bd delete for explicit deletion\n\n## Root Cause 2: Daemon sync race condition overwrites local unpushed changes\n\n**Location:** cmd/bd/daemon_sync.go, performAutoImport()\n\nThe daemon sync's auto-import function pulls from remote without checking for uncommitted local changes. This can overwrite local work that hasn't been pushed yet.\n\n**Fix Applied:** Added warning at lines 565-575 in daemon_sync.go that:\n- Checks for uncommitted changes before pulling\n- Warns user about potential overwrite\n- Suggests running 'bd sync' to commit/push first\n- Continues with pull but user is informed\n\n## Additional Safety Improvements\n\n1. Enhanced repo ID mismatch error message (daemon_sync.go:362-371)\n   - Added warning about deletion risk\n   - Clarified that mismatch can cause incorrect deletions\n\n2. Safety guard in deletions manifest processing (importer.go:886-902)\n   - Prevents deletion of open/in_progress issues in deletions.jsonl\n   - Provides diagnostic information\n   - Suggests recovery options\n\n3. Updated tests (purge_test.go)\n   - Changed test to use closed issue (safe to delete)\n   - Verifies safety guard works correctly\n\n## Testing\n\nAll tests pass:\n- go test ./internal/importer/... ‚úì\n- go build ./cmd/bd/ ‚úì\n\nThe safety guards now prevent both root causes from deleting active work.","status":"closed","priority":0,"issue_type":"bug","created_at":"2025-12-14T23:00:19.36203-08:00","updated_at":"2025-12-14T23:07:43.311616-08:00","closed_at":"2025-12-14T23:07:43.311616-08:00"}
{"id":"bd-ktng","title":"Optimize CLI test suite - eliminate redundant git init calls","description":"Current: Each of 13 CLI tests calls git init (31s total). Solution: Use single test binary built once in init(), skip git operations where possible, or use mock filesystem.","status":"open","priority":2,"issue_type":"task","created_at":"2025-11-04T11:23:13.660276-08:00","updated_at":"2025-11-04T11:23:13.660276-08:00"}
{"id":"bd-kzxd","title":"Sync protection mechanism resurrects deleted issues","description":"During bd sync, the 'Protecting N issue(s) from left snapshot' logic resurrects issues that are in the deletions manifest, causing UNIQUE constraint failures on subsequent syncs.\n\n## Reproduction\n1. Delete an issue with bd delete (creates tombstone + deletions.jsonl entry)\n2. Run bd sync - succeeds\n3. Run bd sync again - fails with 'UNIQUE constraint failed: issues.id'\n\n## Root Cause\nThe protection mechanism (designed to prevent data loss during 3-way merge) keeps a snapshot of issues before sync. When importing after pull, it restores issues from this snapshot even if they're in the deletions manifest.\n\n## Observed Behavior\n- bd-3pd was deleted and added to deletions.jsonl\n- First sync exports tombstone, commits, pulls, imports - succeeds\n- Second sync: protection restores bd-3pd from left snapshot\n- Import tries to create bd-3pd which already exists ‚Üí UNIQUE constraint error\n\n## Expected Behavior\nIssues in deletions manifest should NOT be restored by protection mechanism.\n\n## Workaround\nManually delete from DB: sqlite3 .beads/beads.db 'DELETE FROM issues WHERE id = \"bd-xxx\"'\n\n## Files to Investigate\n- cmd/bd/sync.go - protection logic\n- cmd/bd/snapshot_manager.go - left snapshot handling\n- internal/importer/importer.go - import with protection","status":"closed","priority":1,"issue_type":"bug","created_at":"2025-12-13T10:11:02.550663-08:00","updated_at":"2025-12-13T10:20:51.651662-08:00","closed_at":"2025-12-13T10:20:51.651662-08:00"}
{"id":"bd-l0pg","title":"GH#483: Pre-commit hook should not fail when .beads exists but bd sync fails","description":"Pre-commit hook exit 1 on bd sync --flush-only failure blocks commits even when user removed beads but .beads dir reappears. Should warn not fail. See: https://github.com/steveyegge/beads/issues/483","status":"in_progress","priority":2,"issue_type":"bug","created_at":"2025-12-14T16:32:22.759225-08:00","updated_at":"2025-12-14T16:52:49.799074-08:00"}
{"id":"bd-lfak","title":"bd preflight: PR readiness checks for contributors","description":"## Vision\n\nEncode project-specific institutional knowledge into executable checks. CONTRIBUTING.md is documentation that's read once and forgotten; `bd preflight` is documentation that runs at exactly the right moment.\n\n## Problem Statement\n\nContributors face a \"last mile\" problem - they do the work but stumble on project-specific gotchas at PR time:\n- Nix vendorHash gets stale when go.sum changes\n- Beads artifacts leak into PRs (see bd-umbf for namespace solution)\n- Version mismatches between version.go and default.nix\n- Tests/lint not run locally before pushing\n- Other project-specific checks that only surface when CI fails\n\nThese are too obscure to remember, exist in docs nobody reads end-to-end, and waste CI round-trips.\n\n## Why beads?\n\nBeads already has a foothold in the contributor workflow. It knows:\n- Git state (staged files, branch, dirty status)\n- Project structure\n- The specific issue being worked on\n- Project-specific configuration\n\n## Proposed Interface\n\n### Tier 1: Checklist Mode (v1)\n\n    $ bd preflight\n    PR Readiness Checklist:\n\n    [ ] Tests pass: go test -short ./...\n    [ ] Lint passes: golangci-lint run ./...\n    [ ] No beads pollution: check .beads/issues.jsonl diff\n    [ ] Nix hash current: go.sum unchanged or vendorHash updated\n    [ ] Version sync: version.go matches default.nix\n\n    Run 'bd preflight --check' to validate automatically.\n\n### Tier 2: Check Mode (v2)\n\n    $ bd preflight --check\n    ‚úì Tests pass\n    ‚úì Lint passes\n    ‚ö† Beads pollution: 3 issues in diff - are these project issues or personal?\n    ‚úó Nix hash stale: go.sum changed, vendorHash needs update\n      Fix: sha256-KRR6dXzsSw8OmEHGBEVDBOoIgfoZ2p0541T9ayjGHlI=\n    ‚úì Version sync\n\n    1 error, 1 warning. Run 'bd preflight --fix' to auto-fix where possible.\n\n### Tier 3: Fix Mode (v3)\n\n    $ bd preflight --fix\n    ‚úì Updated vendorHash in default.nix\n    ‚ö† Cannot auto-fix beads pollution - manual review needed\n\n## Checks to Implement\n\n| Check | Description | Auto-fixable |\n|-------|-------------|--------------|\n| tests | Run go test -short ./... | No |\n| lint | Run golangci-lint | Partial (gofmt) |\n| beads-pollution | Detect personal issues in diff | No (see bd-umbf) |\n| nix-hash | Detect stale vendorHash | Yes (if nix available) |\n| version-sync | version.go matches default.nix | Yes |\n| no-debug | No TODO/FIXME/console.log | Warn only |\n| clean-stage | No unintended files staged | Warn only |\n\n## Future: Configuration\n\nMake checks configurable per-project via .beads/preflight.yaml:\n\n    preflight:\n      checks:\n        - name: tests\n          run: go test -short ./...\n          required: true\n        - name: no-secrets\n          pattern: \"**/*.env\"\n          staged: deny\n        - name: custom-check\n          run: ./scripts/validate.sh\n\nThis lets any project using beads define their own preflight checks.\n\n## Implementation Phases\n\n### Phase 1: Static Checklist\n- Implement bd preflight with hardcoded checklist for beads\n- No execution, just prints what to check\n- Update CONTRIBUTING.md to reference it\n\n### Phase 2: Automated Checks\n- Implement bd preflight --check\n- Run tests, lint, detect stale hashes\n- Clear pass/fail/warn output\n\n### Phase 3: Auto-fix\n- Implement bd preflight --fix\n- Fix vendorHash, version sync\n- Integrate with bd-umbf solution for pollution\n\n### Phase 4: Configuration\n- .beads/preflight.yaml support\n- Make it useful for other projects using beads\n- Plugin/hook system for custom checks\n\n## Dependencies\n\n- bd-umbf: Namespace isolation for beads pollution (blocking for full solution)\n\n## Success Metrics\n\n- Fewer CI failures on first PR push\n- Reduced \"fix nix hash\" commits\n- Contributors report preflight caught issues before CI","status":"open","priority":2,"issue_type":"epic","created_at":"2025-12-13T18:01:39.587078-08:00","updated_at":"2025-12-13T18:01:39.587078-08:00","dependencies":[{"issue_id":"bd-lfak","depends_on_id":"bd-umbf","type":"blocks","created_at":"2025-12-13T18:01:46.059901-08:00","created_by":"daemon"}]}
{"id":"bd-llfl","title":"Improve test coverage for cmd/bd CLI (26.2% ‚Üí 50%)","description":"The main CLI package (cmd/bd) has only 26.2% test coverage. CLI commands should have at least 50% coverage to ensure reliability.\n\nKey areas with low/no coverage:\n- daemon_autostart.go (multiple 0% functions)\n- compact.go (several 0% functions)\n- Various command handlers\n\nCurrent coverage: 26.2%\nTarget coverage: 50%","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-13T20:43:03.123341-08:00","updated_at":"2025-12-13T21:01:18.901944-08:00"}
{"id":"bd-lsv4","title":"GH#444: Fix inconsistent status naming in_progress vs in-progress","description":"Documentation uses in-progress (hyphen) but code expects in_progress (underscore). Update all docs to use canonical in_progress. See GitHub issue #444.","status":"open","priority":2,"issue_type":"bug","created_at":"2025-12-16T01:03:14.349425-08:00","updated_at":"2025-12-16T01:03:14.349425-08:00"}
{"id":"bd-lw0x","title":"Fix bd sync race condition with daemon causing dirty working directory","description":"After bd sync completes with sync.branch mode, subsequent bd commands or daemon file watcher would see a hash mismatch and trigger auto-import, which then schedules re-export, dirtying the working directory.\n\n**Root cause:**\n1. bd sync exports JSONL with NEW content (hash H1)\n2. bd sync updates jsonl_content_hash = H1 in DB\n3. bd sync restores JSONL from HEAD (OLD content, hash H0)\n4. Now: file hash = H0, DB hash = H1 (MISMATCH)\n5. Daemon or next CLI command sees mismatch, imports from OLD JSONL\n6. Import triggers re-export ‚Üí file is dirty\n\n**Fix:**\nAfter restoreBeadsDirFromBranch(), update jsonl_content_hash to match the restored file's hash. This ensures daemon and CLI see file hash = DB hash ‚Üí no spurious import/export cycle.\n\nRelated: bd-c83r (multiple daemon prevention)","status":"closed","priority":2,"issue_type":"bug","created_at":"2025-12-13T06:42:17.130839-08:00","updated_at":"2025-12-13T06:43:33.329042-08:00","closed_at":"2025-12-13T06:43:33.329042-08:00"}
{"id":"bd-lxzx","title":"Add close_reason to JSONL export format documentation","description":"PR #551 now persists close_reason to the database, but there's a question about whether this field should be exported to JSONL format.\n\n## Current State\n- close_reason is stored in issues.close_reason column\n- close_reason is also stored in events table (audit trail)\n- The JSONL export format may or may not include close_reason\n\n## Questions\n1. Should close_reason be exported to JSONL format?\n2. If yes, where should it go (root level or nested in events)?\n3. Should there be any special handling to avoid duplication?\n4. How should close_reason be handled during JSONL import?\n\n## Why This Matters\n- JSONL is the git-friendly sync format\n- Other beads instances import from JSONL\n- close_reason is meaningful data that should be preserved across clones\n\n## Suggested Action\n- Check if close_reason is currently exported in JSONL\n- If not, add it to the export schema\n- Document the field in JSONL format spec\n- Add tests for round-trip (export -\u003e import -\u003e verify close_reason)","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-14T14:25:17.414916-08:00","updated_at":"2025-12-14T14:25:17.414916-08:00","dependencies":[{"issue_id":"bd-lxzx","depends_on_id":"bd-z86n","type":"discovered-from","created_at":"2025-12-14T14:25:17.416131-08:00","created_by":"stevey"}]}
{"id":"bd-m8ro","title":"Improve test coverage for internal/rpc (47.5% ‚Üí 60%)","description":"The RPC package has only 47.5% test coverage. RPC is the communication layer for daemon operations.\n\nCurrent coverage: 47.5%\nTarget coverage: 60%","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-13T20:43:09.515299-08:00","updated_at":"2025-12-13T21:01:17.17404-08:00"}
{"id":"bd-mql4","title":"getLocalSyncBranch silently ignores YAML parse errors","description":"In autoimport.go:170-172, YAML parsing errors are silently ignored. If a user has malformed YAML in config.yaml, sync-branch will just silently be empty with no feedback.\n\nRecommendation: Add debug logging since this function is only called during auto-import, and debugging silent failures is painful.\n\nAdd: debug.Logf(\"Warning: failed to parse config.yaml: %v\", err)","status":"open","priority":4,"issue_type":"task","created_at":"2025-12-07T02:03:44.217728-08:00","updated_at":"2025-12-07T02:03:44.217728-08:00"}
{"id":"bd-n386","title":"Improve test coverage for internal/daemon (27.3% ‚Üí 60%)","description":"The daemon package has only 27.3% test coverage. The daemon is critical for background operations and reliability.\n\nKey areas needing tests:\n- Daemon autostart logic\n- Socket handling\n- PID file management\n- Health checks\n\nCurrent coverage: 27.3%\nTarget coverage: 60%","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-13T20:43:00.895238-08:00","updated_at":"2025-12-13T21:01:17.274438-08:00"}
{"id":"bd-n3v","title":"Error committing to sync branch: failed to create worktree","description":"\u003e bd sync --no-daemon\n‚Üí Exporting pending changes to JSONL...\n‚Üí Committing changes to sync branch 'beads-sync'...\nError committing to sync branch: failed to create worktree: failed to create worktree parent directory: mkdir /var/home/matt/dev/beads/fix-ci/.git: not a directory","notes":"**Problem Diagnosed**: The `bd sync` command was failing with \"mkdir /var/home/matt/dev/beads/fix-ci/.git: not a directory\" because it was being executed from the wrong directory.\n\n**Root Cause**: The command was run from `/var/home/matt/dev/beads` (where the `fix-ci` worktree exists) instead of the main repository directory `/var/home/matt/dev/beads/main`. Since `fix-ci` is a git worktree with a `.git` file (not directory), the worktree creation logic failed when trying to create `\u003ccurrent_dir\u003e/.git/beads-worktrees/\u003cbranch\u003e`.\n\n**Solution Verified**: Execute `bd sync` from the main repository directory:\n```bash\ncd main \u0026\u0026 bd sync --dry-run\n```\n","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-05T15:25:24.514998248-07:00","updated_at":"2025-12-05T15:42:32.910166956-07:00"}
{"id":"bd-n4td","title":"Add warning when staleness check errors","description":"## Problem\n\nWhen ensureDatabaseFresh() calls CheckStaleness() and it errors (corrupted metadata, permission issues, etc.), we silently proceed with potentially stale data.\n\n**Location:** cmd/bd/staleness.go:27-32\n\n**Scenarios:**\n- Corrupted metadata table\n- Database locked by another process  \n- Permission issues reading JSONL file\n- Invalid last_import_time format in DB\n\n## Current Code\n\n```go\nisStale, err := autoimport.CheckStaleness(ctx, store, dbPath)\nif err \\!= nil {\n    // If we can't determine staleness, allow operation to proceed\n    // (better to show potentially stale data than block user)\n    return nil\n}\n```\n\n## Fix\n\n```go\nisStale, err := autoimport.CheckStaleness(ctx, store, dbPath)\nif err \\!= nil {\n    fmt.Fprintf(os.Stderr, \"Warning: Could not verify database freshness: %v\\n\", err)\n    fmt.Fprintf(os.Stderr, \"Proceeding anyway. Data may be stale.\\n\\n\")\n    return nil\n}\n```\n\n## Impact\nMedium - users should know when staleness check fails\n\n## Effort\nEasy - 5 minutes","status":"open","priority":2,"issue_type":"bug","created_at":"2025-11-20T20:16:34.889997-05:00","updated_at":"2025-11-20T20:16:34.889997-05:00","dependencies":[{"issue_id":"bd-n4td","depends_on_id":"bd-2q6d","type":"blocks","created_at":"2025-11-20T20:18:20.154723-05:00","created_by":"stevey"}]}
{"id":"bd-nhkh","title":"bd blocked shows empty (GH#545)","description":"bd blocked only shows dependency-blocked issues, not status=blocked issues.\n\nEither:\n- Include status=blocked issues, OR\n- Document/rename to clarify behavior\n\nFix in: cmd/bd/blocked.go","status":"closed","priority":1,"issue_type":"bug","created_at":"2025-12-14T23:00:33.19049-08:00","updated_at":"2025-12-14T23:07:43.313267-08:00","closed_at":"2025-12-14T23:07:43.313267-08:00"}
{"id":"bd-nl2","title":"No logging/debugging for tombstone resurrection events","description":"Per the design document bd-zvg Open Question 1: Should resurrection log a warning? Recommendation was Yes. Currently, when an expired tombstone loses to a live issue (resurrection), there is no logging or debugging output. This makes it hard to understand why an issue reappeared. Recommendation: Add optional debug logging when resurrection occurs, e.g., Issue bd-abc resurrected (tombstone expired). Files: internal/merge/merge.go:359-366, 371-378, 400-405, 410-415","status":"open","priority":4,"issue_type":"feature","created_at":"2025-12-05T16:36:52.27525-08:00","updated_at":"2025-12-05T16:36:52.27525-08:00"}
{"id":"bd-nuh1","title":"GH#403: bd doctor --fix circular error message","description":"bd doctor --fix suggests running bd doctor --fix for deletions manifest issue. Fix to provide actual resolution. See GitHub issue #403.","status":"open","priority":2,"issue_type":"bug","created_at":"2025-12-16T01:03:16.290018-08:00","updated_at":"2025-12-16T01:03:16.290018-08:00"}
{"id":"bd-o4qy","title":"Improve CheckStaleness error handling","description":"## Problem\n\nCheckStaleness returns 'false' (not stale) for multiple error conditions instead of returning errors. This masks problems.\n\n**Location:** internal/autoimport/autoimport.go:253-285\n\n## Edge Cases That Return False\n\n1. **Invalid last_import_time format** (line 259-262)\n2. **No JSONL file found** (line 267-277)  \n3. **JSONL stat fails** (line 279-282)\n\n## Fix\n\nReturn errors for abnormal conditions:\n\n```go\nlastImportTime, err := time.Parse(time.RFC3339, lastImportStr)\nif err != nil {\n    return false, fmt.Errorf(\"corrupted last_import_time: %w\", err)\n}\n\nif jsonlPath == \"\" {\n    return false, fmt.Errorf(\"no JSONL file found\")\n}\n\nstat, err := os.Stat(jsonlPath)\nif err != nil {\n    return false, fmt.Errorf(\"cannot stat JSONL: %w\", err)\n}\n```\n\n## Impact\nMedium - edge cases are rare but should be handled\n\n## Effort  \n30 minutes - requires updating callers in RPC server","status":"open","priority":2,"issue_type":"bug","created_at":"2025-11-20T20:17:27.606219-05:00","updated_at":"2025-11-20T20:17:27.606219-05:00","dependencies":[{"issue_id":"bd-o4qy","depends_on_id":"bd-2q6d","type":"blocks","created_at":"2025-11-20T20:18:26.81065-05:00","created_by":"stevey"}]}
{"id":"bd-o55a","title":"GH#509: bd doesn't find .beads when running from nested worktrees","description":"When worktrees are nested under main repo (.worktrees/feature/), bd stops at worktree git root instead of continuing to find .beads in parent. See GitHub issue #509 for detailed fix suggestion.","status":"open","priority":2,"issue_type":"bug","created_at":"2025-12-16T01:03:20.281591-08:00","updated_at":"2025-12-16T01:03:20.281591-08:00"}
{"id":"bd-o78","title":"Enhance `bd doctor` to verify Claude Code integration","description":"Add checks to `bd doctor` that verify Claude Code integration is properly set up when .claude/ directory or Claude environment is detected.","status":"open","priority":2,"issue_type":"task","created_at":"2025-11-11T23:30:05.782406-08:00","updated_at":"2025-11-12T00:12:07.717579-08:00","dependencies":[{"issue_id":"bd-o78","depends_on_id":"bd-90v","type":"parent-child","created_at":"2025-11-11T23:31:27.886095-08:00","created_by":"daemon"}]}
{"id":"bd-ola6","title":"Implement transaction retry logic for SQLITE_BUSY","description":"BEGIN IMMEDIATE fails immediately on SQLITE_BUSY instead of retrying with exponential backoff.\n\nLocation: internal/storage/sqlite/sqlite.go:223-225\n\nProblem:\n- Under concurrent write load, BEGIN IMMEDIATE can fail with SQLITE_BUSY\n- Current implementation fails immediately instead of retrying\n- Results in spurious failures under normal concurrent usage\n\nSolution: Implement exponential backoff retry:\n- Retry up to N times (e.g., 5)\n- Backoff: 10ms, 20ms, 40ms, 80ms, 160ms\n- Check for context cancellation between retries\n- Only retry on SQLITE_BUSY/database locked errors\n\nImpact: Spurious failures under concurrent write load\n\nEffort: 3 hours","status":"open","priority":1,"issue_type":"feature","created_at":"2025-11-16T14:51:31.247147-08:00","updated_at":"2025-11-16T14:51:31.247147-08:00"}
{"id":"bd-otf4","title":"Code Review: PR #481 - Context Engineering Optimizations","description":"Comprehensive code review of the merged context engineering PR (PR #481) that reduces MCP context usage by 80-90%.\n\n## Summary\nThe PR successfully implements lazy tool schema loading and minimal issue models to reduce context window usage. Overall implementation is solid and well-tested.\n\n## Positive Findings\n‚úÖ Well-designed models (IssueMinimal, CompactedResult)\n‚úÖ Comprehensive test coverage (28 tests, all passing)\n‚úÖ Clear documentation and comments\n‚úÖ Backward compatibility preserved (show() still returns full Issue)\n‚úÖ Sensible defaults (COMPACTION_THRESHOLD=20, PREVIEW_COUNT=5)\n‚úÖ Tool catalog complete with all 15 tools documented\n\n## Issues Identified\nSee linked issues for specific followup tasks.\n\n## Context Engineering Architecture\n- discover_tools(): List tool names only (~500 bytes vs ~15KB)\n- get_tool_info(name): Get specific tool details on-demand\n- IssueMinimal: Lightweight model for list views (~80 bytes vs ~400 bytes)\n- CompactedResult: Auto-compacts results with \u003e20 issues\n- _to_minimal(): Conversion function (efficient, no N+1 issues)","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-14T14:24:13.523532-08:00","updated_at":"2025-12-14T14:24:13.523532-08:00"}
{"id":"bd-pdr2","title":"Consider backwards compatibility for ready() and list() return type change","description":"PR #481 changed the return types of `ready()` and `list()` from `list[Issue]` to `list[IssueMinimal] | CompactedResult`. This is a breaking change for MCP clients.\n\n## Impact Assessment\nBreaking change affects:\n- Any MCP client expecting `list[Issue]` from ready()\n- Any MCP client expecting `list[Issue]` from list()\n- Client code that accesses full Issue fields (description, design, acceptance_criteria, timestamps, dependencies, dependents)\n\n## Current Behavior\n- ready() returns `list[IssueMinimal] | CompactedResult`\n- list() returns `list[IssueMinimal] | CompactedResult`\n- show() still returns full `Issue` (good)\n\n## Considerations\n**Pros of current approach:**\n- Forces clients to use show() for full details (good for context efficiency)\n- Simple mental model (always use show for full data)\n- Documentation warns about this\n\n**Cons:**\n- Clients expecting list[Issue] will break\n- No graceful degradation option\n- No migration period\n\n## Potential Solutions\n1. Add optional parameter `full_details=false` to ready/list (would increase payload)\n2. Create separate tools: ready_minimal/list_minimal + ready_full/list_full\n3. Accept breaking change and document upgrade path (current approach)\n4. Version the MCP server and document migration guide\n\n## Recommendation\nCurrent approach (solution 3) is reasonable if:\n- Changelog clearly documents the breaking change\n- Migration guide provided to clients\n- Error handling is graceful for clients expecting specific fields","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-14T14:24:56.460465-08:00","updated_at":"2025-12-14T14:24:56.460465-08:00","dependencies":[{"issue_id":"bd-pdr2","depends_on_id":"bd-otf4","type":"discovered-from","created_at":"2025-12-14T14:24:56.461959-08:00","created_by":"stevey"}]}
{"id":"bd-r46","title":"Support --reason flag in daemon mode for reopen command","description":"The reopen.go command has a TODO at line 61 to add reason as a comment once RPC supports AddComment. Currently --reason flag is ignored in daemon mode with a warning.","status":"open","priority":2,"issue_type":"feature","created_at":"2025-11-21T18:55:10.773626-05:00","updated_at":"2025-11-21T18:55:10.773626-05:00"}
{"id":"bd-r4od","title":"Parameterize SQLite busy_timeout in store.go","description":"Modify sqlite.New() to accept configurable busy_timeout.\n\n## Current State\n`internal/storage/sqlite/store.go` hardcodes:\n```go\nconnStr = \"file:\" + path + \"?_pragma=foreign_keys(ON)\u0026_pragma=busy_timeout(30000)\u0026...\"\n```\n\n## Implementation Options\n\n### Option A: Add timeout parameter to New()\n```go\nfunc New(ctx context.Context, path string, busyTimeout time.Duration) (*SQLiteStorage, error)\n```\nPro: Simple, explicit\nCon: Changes function signature (breaking change for callers)\n\n### Option B: Options struct pattern\n```go\ntype Options struct {\n    BusyTimeout time.Duration // default 30s\n}\nfunc New(ctx context.Context, path string, opts *Options) (*SQLiteStorage, error)\n```\nPro: Extensible, nil means defaults\nCon: More boilerplate\n\n### Recommendation: Option A with default\n```go\nfunc New(ctx context.Context, path string) (*SQLiteStorage, error) {\n    return NewWithOptions(ctx, path, 30*time.Second)\n}\n\nfunc NewWithOptions(ctx context.Context, path string, busyTimeout time.Duration) (*SQLiteStorage, error)\n```\n\n## Acceptance Criteria\n- busy_timeout is parameterized in connection string\n- 0 timeout means no waiting (immediate SQLITE_BUSY)\n- All existing callers continue to work (via default wrapper)\n\nPart of bd-olc1","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-13T17:54:46.896222-08:00","updated_at":"2025-12-13T18:05:19.443831-08:00","closed_at":"2025-12-13T18:05:19.443831-08:00","dependencies":[{"issue_id":"bd-r4od","depends_on_id":"bd-59er","type":"blocks","created_at":"2025-12-13T17:55:26.550018-08:00","created_by":"daemon"}]}
{"id":"bd-s02","title":"Manual task","description":"","status":"closed","priority":2,"issue_type":"task","created_at":"2025-11-03T20:15:10.022202-08:00","updated_at":"2025-12-13T23:29:56.877597-08:00","closed_at":"2025-12-13T23:29:56.877597-08:00"}
{"id":"bd-s2t","title":"wish: a 'continue' or similar cmd/flag which means alter last issue","description":"so many time I create an issue and then have another thought: 'oh, before I did X and it crashed there was ZZZ happening' or 'actually that is P4 not P2'. It would be nice if when `bd {cmd}` is used without a {title} or {id} it just adds or updates the most recently touched issue.","status":"open","priority":3,"issue_type":"task","created_at":"2025-12-08T06:46:37.529160416-07:00","updated_at":"2025-12-08T06:46:37.529160416-07:00"}
{"id":"bd-sh4c","title":"Improve test coverage for cmd/bd/setup (28.4% ‚Üí 50%)","description":"The setup package has only 28.4% test coverage. Setup commands are critical for first-time user experience.\n\nCurrent coverage: 28.4%\nTarget coverage: 50%","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-13T20:43:04.409346-08:00","updated_at":"2025-12-13T21:01:18.98833-08:00"}
{"id":"bd-siz1","title":"GH#532: bd sync circular error (suggests running bd sync)","description":"bd sync error message recommends running bd sync to fix the bd sync error. Fix error handling to provide useful guidance. See GitHub issue #532.","status":"open","priority":2,"issue_type":"bug","created_at":"2025-12-16T01:04:00.543573-08:00","updated_at":"2025-12-16T01:04:00.543573-08:00"}
{"id":"bd-svb5","title":"GH#505: Add bd reset/wipe command","description":"Add command to cleanly reset/wipe beads database. User reports painful manual process to start fresh. See GitHub issue #505.","status":"open","priority":2,"issue_type":"feature","created_at":"2025-12-16T01:03:42.160966-08:00","updated_at":"2025-12-16T01:03:42.160966-08:00"}
{"id":"bd-t4u1","title":"False positive detection by Kaspersky Antivirus (Trojan)","description":"Kaspersky Antivirus falsely detects beads (bd.exe v0.23.1) as a Trojan (PDM:Trojan.Win32.Generic) and removes it.\nEvent: Malicious object detected\nComponent: System Watcher\nObject name: bd.exe\n","status":"open","priority":1,"issue_type":"task","created_at":"2025-11-20T18:56:12.498187-05:00","updated_at":"2025-11-20T18:56:12.498187-05:00"}
{"id":"bd-tbz3","title":"bd init UX Improvements","description":"bd init leaves users with incomplete setup, requiring manual bd doctor --fix. Issues found: (1) git hooks not installed if user declines prompt, (2) no auto-migration when CLI is upgraded, (3) stale merge driver configs from old versions. Fix by making bd init more robust with better defaults and auto-migration.","status":"open","priority":1,"issue_type":"epic","created_at":"2025-11-21T23:16:00.333543-08:00","updated_at":"2025-11-21T23:16:37.811233-08:00"}
{"id":"bd-thgk","title":"Improve test coverage for internal/compact (18.2% ‚Üí 70%)","description":"The compact package has only 18.2% test coverage. This is a core package handling issue compaction and should have at least 70% coverage.\n\nKey functions needing tests:\n- runCompactSingle (0%)\n- runCompactAll (0%)\n- runCompactRPC (0%)\n- runCompactStatsRPC (0%)\n- runCompactAnalyze (0%)\n- runCompactApply (0%)\n- pruneDeletionsManifest (0%)\n\nCurrent coverage: 18.2%\nTarget coverage: 70%","status":"open","priority":1,"issue_type":"task","created_at":"2025-12-13T20:42:58.455767-08:00","updated_at":"2025-12-13T21:01:15.070551-08:00"}
{"id":"bd-tm2p","title":"Polecats get stuck on interactive shell prompts (cp/mv/rm -i)","description":"During swarm operations, polecats frequently get stuck waiting for interactive prompts from shell commands like:\n- cp prompting 'overwrite file? (y/n)'\n- mv prompting 'overwrite file? (y/n)'  \n- rm prompting 'remove file?'\n\nThis happens because macOS aliases or shell configs may have -i flags set by default.\n\nRoot cause: Claude Code runs commands that trigger interactive confirmation prompts, but cannot respond to them, causing the agent to hang indefinitely.\n\nObserved in: Multiple polecats during GH issues swarm (Dec 2024)\n- Derrick, Roustabout, Prospector, Warboy all got stuck on y/n prompts\n\nSuggested fixes:\n1. AGENTS.md should instruct agents to always use -f flag with cp/mv/rm\n2. Polecat startup could set shell aliases to use non-interactive versions\n3. bd prime hook could include guidance about non-interactive commands\n4. Consider detecting stuck prompts and auto-recovering","status":"open","priority":1,"issue_type":"bug","created_at":"2025-12-14T16:51:24.572271-08:00","updated_at":"2025-12-14T16:51:24.572271-08:00"}
{"id":"bd-tnsq","title":"bd cleanup fails with CHECK constraint on status/closed_at mismatch","description":"## Problem\n\nRunning bd cleanup --force fails with:\n\nError: failed to create tombstone for bd-okh: sqlite3: constraint failed: CHECK constraint failed: (status = 'closed') = (closed_at IS NOT NULL)\n\n## Root Cause\n\nThe database has a CHECK constraint ensuring closed issues have closed_at set and non-closed issues do not. When bd cleanup tries to convert a closed issue to a tombstone, this constraint fails.\n\n## Impact\n\n- bd cleanup --force cannot complete\n- 722 closed issues cannot be cleaned up\n- Blocks routine maintenance\n\n## Investigation Needed\n\n1. Check the bd-okh record in the database\n2. Determine if this is data corruption or a bug in tombstone creation\n\n## Proposed Solutions\n\n1. If data corruption: Add a bd doctor --fix check that repairs status/closed_at mismatches\n2. If code bug: Fix the tombstone creation to properly handle the constraint\n\n## Files to Investigate\n\n- internal/storage/sqlite/sqlite.go - DeleteIssue / tombstone creation\n- Schema CHECK constraint definition\n\n## Acceptance Criteria\n\n- Identify root cause (data vs code bug)\n- bd cleanup --force completes successfully\n- bd doctor detects status/closed_at mismatches","status":"closed","priority":1,"issue_type":"bug","created_at":"2025-12-14T00:27:46.359724-08:00","updated_at":"2025-12-14T00:41:54.584366-08:00","closed_at":"2025-12-14T00:34:59.658781-08:00"}
{"id":"bd-tvu3","title":"Improve test coverage for internal/beads (48.1% ‚Üí 70%)","description":"The beads package is a core package with 48.1% coverage. As the primary package for issue management, it should have at least 70% coverage.\n\nCurrent coverage: 48.1%\nTarget coverage: 70%","status":"open","priority":1,"issue_type":"task","created_at":"2025-12-13T20:42:59.739142-08:00","updated_at":"2025-12-13T21:01:14.874359-08:00"}
{"id":"bd-u0g9","title":"GH#405: Prefix parsing with hyphens treats first segment as prefix","description":"Prefix me-py-toolkit gets parsed as just me- when detecting mismatches. Fix prefix parsing to handle multi-hyphen prefixes. See GitHub issue #405.","status":"open","priority":2,"issue_type":"bug","created_at":"2025-12-16T01:03:18.354066-08:00","updated_at":"2025-12-16T01:03:18.354066-08:00"}
{"id":"bd-umbf","title":"Design contributor namespace isolation for beads pollution prevention","description":"## Problem\n\nWhen contributors work on beads-the-project using beads-the-tool, their personal work-tracking issues leak into PRs. The .beads/issues.jsonl is intentionally tracked (it's the project's issue database), but contributors' local issues pollute the diff.\n\nThis is a recursion problem unique to self-hosting projects.\n\n## Possible Solutions to Explore\n\n1. **Contributor namespaces** - Each contributor gets a private prefix (e.g., `bd-steve-xxxx`) that's gitignored or filtered\n2. **Separate database** - Contributors use BEADS_DIR pointing elsewhere for personal tracking\n3. **Issue ownership/visibility flags** - Mark issues as \"local-only\" vs \"project\"\n4. **Prefix-based filtering** - Configure which prefixes are committed vs ignored\n\n## Design Considerations\n\n- Should be zero-friction for contributors (no manual setup)\n- Must not break existing workflows\n- Needs to work with sync/collaboration features\n- Consider: what if a \"personal\" issue graduates to \"project\" issue?\n\n## Expansion Needed\n\nThis is a placeholder. Needs detailed design exploration before implementation.","status":"open","priority":2,"issue_type":"feature","created_at":"2025-12-13T18:00:29.638743-08:00","updated_at":"2025-12-13T18:00:41.345673-08:00"}
{"id":"bd-ut5","title":"Test label update feature","description":"","status":"closed","priority":3,"issue_type":"task","created_at":"2025-11-21T22:07:25.488849-05:00","updated_at":"2025-12-13T23:29:56.878215-08:00","closed_at":"2025-12-13T23:29:56.878215-08:00"}
{"id":"bd-vckm","title":"Improve sync branch divergence recovery UX","description":"When the sync branch diverges significantly from remote (e.g., 89 local vs 36 remote commits), bd sync fails with a confusing rebase conflict error.\n\n**Current behavior:**\n```\nError committing to sync branch: failed to push from worktree: push failed and recovery rebase also failed\nerror: could not apply 8712f35... bd sync: 2025-12-13 07:30:04\nCONFLICT (content): Merge conflict in .beads/issues.jsonl\n```\n\nUser is left in a broken state with no clear recovery path.\n\n**Expected behavior:**\n1. Detect significant divergence before attempting sync\n2. Offer options: 'Sync branch diverged. Choose: (1) Reset to remote (2) Force push local (3) Manual merge'\n3. Provide clear recovery commands if automatic recovery fails\n\n**Context:** This happened after multiple clones synced different states. The workaround was manually resetting the sync branch worktree to remote.","status":"closed","priority":3,"issue_type":"feature","created_at":"2025-12-15T17:29:01.803478-08:00","updated_at":"2025-12-16T01:04:45.251662-08:00","closed_at":"2025-12-16T01:04:45.251662-08:00"}
{"id":"bd-vs9","title":"Fix unparam unused parameter in cmd/bd/doctor.go:541","description":"Linting issue: checkHooksQuick - path is unused (unparam) at cmd/bd/doctor.go:541:22. Error: func checkHooksQuick(path string) string {","status":"open","priority":0,"issue_type":"bug","created_at":"2025-12-07T15:35:17.02177046-07:00","updated_at":"2025-12-07T15:35:17.02177046-07:00"}
{"id":"bd-wsqt","title":"bd sync outputs excessive 'Skipping' messages for tombstoned issues","description":"During sync, every tombstoned issue outputs a 'Skipping bd-xxx (in deletions manifest)' message. With 96+ tombstones, this creates ~200 lines of noise that obscures the actual sync status.\n\n**Current behavior:**\n```\nSkipping bd-0ih (in deletions manifest: deleted 0001-01-01 by )\nSkipping bd-0is (in deletions manifest: deleted 0001-01-01 by )\n... (96 more lines)\n‚úì Sync complete\n```\n\n**Expected behavior:**\n- Suppress individual skip messages by default\n- Show summary: 'Skipped 96 tombstoned issues'\n- Or add --verbose flag to show individual skips\n\n**Impact:** Makes sync output unreadable, hard to spot actual errors or warnings.","status":"closed","priority":2,"issue_type":"bug","created_at":"2025-12-15T17:28:34.592319-08:00","updated_at":"2025-12-16T00:41:33.166393-08:00","closed_at":"2025-12-16T00:41:33.166393-08:00"}
{"id":"bd-wv9l","title":"Code Review Sweep: thorough","description":"Perform thorough code review sweep based on accumulated activity.\n\n**AI Reasoning:**\nSignificant code activity with 7608 lines added and 120 files changed indicates substantial modifications. Multiple high-churn areas (cmd/bd, internal/rpc) suggest potential for subtle issues and emerging patterns that warrant review.\n\n**Scope:** thorough\n**Target Areas:** cmd/bd, internal/rpc, .beads\n**Estimated Files:** 12\n**Estimated Cost:** $5\n\n**Task:**\nReview files for non-obvious issues that agents miss during focused work:\n- Inefficiencies (algorithmic, resource usage)\n- Subtle bugs (race conditions, off-by-one, copy-paste)\n- Poor patterns (coupling, complexity, duplication)\n- Missing best practices (error handling, docs, tests)\n- Unnamed anti-patterns\n\nFile discovered issues with detailed reasoning and suggestions.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-11-21T23:23:16.056392-08:00","updated_at":"2025-12-13T23:33:16.519977-08:00","closed_at":"2025-12-13T23:33:16.519977-08:00"}
{"id":"bd-xctp","title":"GH#519: bd sync fails when sync.branch is currently checked-out branch","description":"","status":"closed","priority":2,"issue_type":"bug","created_at":"2025-12-16T01:06:05.319281-08:00","updated_at":"2025-12-16T01:09:33.691906-08:00","closed_at":"2025-12-16T01:09:33.691906-08:00"}
{"id":"bd-xj2e","title":"GH#522: Add --type flag to bd update command","description":"Add --type flag to bd update for changing issue type (task/epic/bug/feature). Storage layer already supports it. See GitHub issue #522.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-16T01:03:12.506583-08:00","updated_at":"2025-12-16T01:25:30.839681-08:00","closed_at":"2025-12-16T01:21:47.72135-08:00"}
{"id":"bd-xoyh","title":"GH#519: bd sync fails when sync.branch equals current branch","description":"bd sync tries to create worktree when sync.branch matches current checkout, fails with 'already used by worktree'. Should detect and commit directly. See: https://github.com/steveyegge/beads/issues/519","status":"closed","priority":2,"issue_type":"bug","created_at":"2025-12-14T16:31:34.574414-08:00","updated_at":"2025-12-16T01:25:30.839077-08:00","closed_at":"2025-12-14T17:29:15.960487-08:00"}
{"id":"bd-xxal","title":"bd ready includes blocked issues (GH#544)","description":"Issues with 'blocks' dependencies still appear in bd ready. The ready query should exclude issues that have unresolved blockers.\n\nFix in: cmd/bd/ready.go or internal query logic.","status":"closed","priority":1,"issue_type":"bug","created_at":"2025-12-14T23:00:26.048532-08:00","updated_at":"2025-12-14T23:07:43.312979-08:00","closed_at":"2025-12-14T23:07:43.312979-08:00"}
{"id":"bd-y2v","title":"Refactor duplicate JSONL-from-git parsing code","description":"Both readFirstIssueFromGit() in init.go and importFromGit() in autoimport.go have similar code patterns for:\n1. Running git show \u003cref\u003e:\u003cpath\u003e\n2. Scanning the output with bufio.Scanner\n3. Parsing JSON lines\n\nCould be refactored to share a helper like:\n- readJSONLFromGit(gitRef, path string) ([]byte, error)\n- Or a streaming version: streamJSONLFromGit(gitRef, path string) (io.Reader, error)\n\nFiles:\n- cmd/bd/autoimport.go:225-256 (importFromGit)\n- cmd/bd/init.go:1212-1243 (readFirstIssueFromGit)\n\nPriority is low since code duplication is minimal and both functions work correctly.","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-05T14:51:18.41124-08:00","updated_at":"2025-12-05T14:51:18.41124-08:00"}
{"id":"bd-y6t6","title":"GH#524: Package for Windows (winget)","description":"Request to publish beads on winget for easy Windows installation. See: https://github.com/steveyegge/beads/issues/524","status":"in_progress","priority":3,"issue_type":"feature","created_at":"2025-12-14T16:31:28.596258-08:00","updated_at":"2025-12-14T16:52:49.798255-08:00"}
{"id":"bd-yck","title":"Fix checkExistingBeadsData to be worktree-aware","description":"The checkExistingBeadsData function in cmd/bd/init.go checks for .beads in the current working directory, but for worktrees it should check the main repository root instead. This prevents proper worktree compatibility.","status":"open","priority":2,"issue_type":"bug","created_at":"2025-12-07T16:48:32.082776345-07:00","updated_at":"2025-12-07T16:48:32.082776345-07:00"}
{"id":"bd-ykd9","title":"Add bd doctor --fix flag to automatically repair issues","description":"Implement a --fix flag for bd doctor that can automatically repair detected issues.\n\nRequirements:\n- Add --fix flag to bd doctor command\n- Show all fixable issues and prompt for confirmation before applying fixes\n- Organize fix implementations under doctor/fix/\u003ctype_of_fix\u003e.go\n- Each fix type should have its own file (e.g., doctor/fix/hooks.go, doctor/fix/sync.go)\n- Display what will be fixed and ask user to confirm (Y/n) before proceeding\n- Support fixing issues like:\n  - Missing or broken git hooks\n  - Sync problems with remote\n  - File permission issues\n  - Any other auto-repairable issues doctor detects\n\nImplementation notes:\n- Maintain separation between detection (existing doctor code) and repair (new fix code)\n- Each fix should be idempotent and safe to run multiple times\n- Provide clear output about what was fixed\n- Log any fixes that fail with actionable error messages","status":"open","priority":2,"issue_type":"feature","created_at":"2025-11-14T18:17:48.411264-08:00","updated_at":"2025-11-14T18:17:58.88609-08:00"}
{"id":"bd-z0yn","title":"Channel isolation test - beads","description":"","notes":"Resetting stale in_progress status from old executor run (13 days old)","status":"closed","priority":2,"issue_type":"task","created_at":"2025-11-08T04:21:17.327983-08:00","updated_at":"2025-12-13T23:29:56.876192-08:00","closed_at":"2025-12-13T23:29:56.876192-08:00"}
{"id":"bd-z3s3","title":"Create deployment scripts for GCP","description":"Automated provisioning scripts for GCP Compute Engine deployment.\n\nAcceptance Criteria:\n- Terraform/gcloud scripts\n- Static IP allocation\n- Firewall rules\n- NGINX reverse proxy config\n- TLS setup (Let's Encrypt)\n- Systemd service file\n\nFile: deployment/agent-mail/gcp/","status":"closed","priority":3,"issue_type":"task","created_at":"2025-11-07T22:43:43.294839-08:00","updated_at":"2025-12-14T00:32:11.049764-08:00","closed_at":"2025-12-13T23:30:58.727475-08:00"}
{"id":"bd-z86n","title":"Code Review: PR #551 - Persist close_reason to issues table","description":"Code review of PR #551 which fixes close_reason persistence bug.\n\n## Summary\nThe PR correctly fixes a bug where close_reason was only stored in the events table, not in the issues.close_reason column. This caused `bd show --json` to return empty close_reason.\n\n## What Was Fixed\n- ‚úÖ CloseIssue now updates both close_reason and closed_at\n- ‚úÖ ReOpenIssue clears both close_reason and closed_at\n- ‚úÖ Comprehensive tests added for both storage and CLI layers\n- ‚úÖ Clear documentation in queries.go about dual storage strategy\n\n## Quality Assessment\n‚úÖ Tests cover both storage layer and CLI JSON output\n‚úÖ Handles reopen case (clearing close_reason)\n‚úÖ Good comments explaining dual-storage design\n‚úÖ No known issues\n\n## Potential Followups\nSee linked issues for suggestions.","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-14T14:25:06.887069-08:00","updated_at":"2025-12-14T14:25:06.887069-08:00"}
{"id":"bd-zbyb","title":"GH#522: Add --type flag to bd update command","description":"Allow changing issue type (task/epic/bug/feature) via bd update --type. Storage layer already supports it. Needed for TUI tools like Abacus. See: https://github.com/steveyegge/beads/issues/522","status":"in_progress","priority":2,"issue_type":"feature","created_at":"2025-12-14T16:31:31.71456-08:00","updated_at":"2025-12-14T16:52:49.797533-08:00"}
{"id":"bd-ziy5","title":"GH#409: bd init uses issues.jsonl but docs say beads.jsonl","description":"bd init creates config referencing issues.jsonl but README/docs reference beads.jsonl as canonical. Standardize naming. See GitHub issue #409.","status":"open","priority":2,"issue_type":"bug","created_at":"2025-12-16T01:03:58.109954-08:00","updated_at":"2025-12-16T01:03:58.109954-08:00"}
{"id":"bd-zsle","title":"GH#516: Automate 'landing the plane' setup in AGENTS.md","description":"bd init or /beads:init should auto-add landing-the-plane instructions to AGENTS.md (and @AGENTS.md for web Claude). Reduces manual setup. See: https://github.com/steveyegge/beads/issues/516","status":"in_progress","priority":2,"issue_type":"feature","created_at":"2025-12-14T16:31:57.541154-08:00","updated_at":"2025-12-14T16:52:49.79956-08:00"}
{"id":"bd-zwtq","title":"Run bd doctor at end of bd init to verify setup","description":"Run bd doctor diagnostics at end of bd init (after line 398 in init.go). If issues found, warn user immediately: '‚ö† Setup incomplete. Run bd doctor --fix to complete setup.' Catches configuration problems before user encounters them in normal workflow.","status":"open","priority":1,"issue_type":"feature","created_at":"2025-11-21T23:16:09.596778-08:00","updated_at":"2025-11-21T23:16:27.781976-08:00","dependencies":[{"issue_id":"bd-zwtq","depends_on_id":"bd-tbz3","type":"parent-child","created_at":"2025-11-21T23:16:09.597617-08:00","created_by":"daemon"}]}
